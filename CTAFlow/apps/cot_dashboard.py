"""Dash application for exploring COT features generated by :class:`COTProcessor`.

The dashboard exposes controls for selecting a ticker and analysis date range and
visualizes each feature group returned by :func:`CTAFlow.features.signals_processing.COTProcessor.calculate_enhanced_cot_features`.

Usage
-----
Run the app with::

    python -m CTAFlow.apps.cot_dashboard

The app will attempt to load preprocessed COT metrics for the requested ticker
from the local CTAFlow data store. When metrics are not available a synthetic
sample dataset is generated so the visualizations remain interactive.
"""

from __future__ import annotations

from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import numpy as np
import pandas as pd
from dash import Dash, Input, Output, dcc, html
from plotly.subplots import make_subplots
import plotly.graph_objects as go

from CTAFlow.features.signals_processing import COTProcessor

try:  # Optional dependency for real COT metrics if the data store exists
    from CTAFlow.data import DataClient  # type: ignore
except Exception:  # pragma: no cover - the dashboard works without the data store
    DataClient = None  # type: ignore

try:  # Optional mapping of tickers to COT codes for DataClient fallback
    from CTAFlow.config import TICKER_TO_CODE  # type: ignore
except Exception:  # pragma: no cover - config may be unavailable in minimal installs
    TICKER_TO_CODE = {}  # type: ignore


# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------

FEATURE_GROUPS: Tuple[str, ...] = (
    "positioning",
    "flows",
    "extremes",
    "market_structure",
    "interactions",
    "spreads",
)
DEFAULT_TICKER = "CL_F"
DEFAULT_PERIODS = 160  # roughly three years of weekly observations

cot_processor = COTProcessor()


@dataclass
class FeatureSplit:
    """Container describing how feature columns should be visualized."""

    line: List[str]
    bar: List[str]
    pie: List[str]

    def is_empty(self) -> bool:
        return not (self.line or self.bar or self.pie)


def _get_data_directory() -> Path:
    return Path(__file__).resolve().parents[1] / "data"


@lru_cache(maxsize=16)
def _generate_mock_cot_data(ticker: str, periods: int = DEFAULT_PERIODS) -> pd.DataFrame:
    """Generate a deterministic synthetic COT dataset for demonstration purposes."""

    rng = np.random.default_rng(abs(hash(ticker)) % (2**32))
    index = pd.date_range(end=pd.Timestamp.today().normalize(), periods=periods, freq="W-FRI")

    # Create smooth baseline series to mimic COT style positioning data
    market_participation = np.clip(200_000 + np.cumsum(rng.normal(0, 4_000, periods)), 50_000, None)
    commercial_longs = np.clip(70_000 + np.cumsum(rng.normal(0, 2_000, periods)), 20_000, None)
    commercial_shorts = np.clip(60_000 + np.cumsum(rng.normal(0, 2_000, periods)), 15_000, None)
    mm_longs = np.clip(55_000 + np.cumsum(rng.normal(0, 2_500, periods)), 10_000, None)
    mm_shorts = np.clip(48_000 + np.cumsum(rng.normal(0, 2_500, periods)), 10_000, None)
    swap_longs = np.clip(25_000 + np.cumsum(rng.normal(0, 1_200, periods)), 5_000, None)
    swap_shorts = np.clip(20_000 + np.cumsum(rng.normal(0, 1_200, periods)), 5_000, None)
    other_longs = np.clip(15_000 + np.cumsum(rng.normal(0, 900, periods)), 2_000, None)
    other_shorts = np.clip(10_000 + np.cumsum(rng.normal(0, 900, periods)), 2_000, None)
    spreads = np.clip(5_000 + np.cumsum(rng.normal(0, 500, periods)), 1_000, None)
    non_reportable_longs = np.clip(12_000 + np.cumsum(rng.normal(0, 800, periods)), 1_000, None)
    non_reportable_shorts = np.clip(11_000 + np.cumsum(rng.normal(0, 800, periods)), 1_000, None)

    total_reportable_longs = mm_longs + commercial_longs + swap_longs + other_longs
    total_reportable_shorts = mm_shorts + commercial_shorts + swap_shorts + other_shorts

    df = pd.DataFrame(
        {
            "market_participation": market_participation,
            "producer_merchant_processor_user_longs": commercial_longs,
            "producer_merchant_processor_user_shorts": commercial_shorts,
            "money_manager_longs": mm_longs,
            "money_manager_shorts": mm_shorts,
            "money_manager_spreads": spreads,
            "swap_dealer_longs": swap_longs,
            "swap_dealer_shorts": swap_shorts,
            "other_reportable_longs": other_longs,
            "other_reportable_shorts": other_shorts,
            "total_reportable_longs": total_reportable_longs,
            "total_reportable_shorts": total_reportable_shorts,
            "non_reportable_longs": non_reportable_longs,
            "non_reportable_shorts": non_reportable_shorts,
        },
        index=index,
    )

    return df.sort_index()


def _load_csv_if_available(ticker: str) -> pd.DataFrame | None:
    """Attempt to load COT data from a CSV file in the project data directory."""

    data_dir = _get_data_directory()
    candidates = [
        data_dir / f"{ticker}.csv",
        data_dir / f"{ticker.lower()}.csv",
        data_dir / f"{ticker.upper()}_cot.csv",
        data_dir / f"{ticker.lower()}_cot.csv",
    ]

    for path in candidates:
        if path.exists():
            df = pd.read_csv(path)
            df = df.copy()
            if "date" in df.columns:
                df.index = pd.to_datetime(df.pop("date"))
            elif "Date" in df.columns:
                df.index = pd.to_datetime(df.pop("Date"))
            elif "Report_Date_as_YYYY-MM-DD" in df.columns:
                df.index = pd.to_datetime(df.pop("Report_Date_as_YYYY-MM-DD"))
            else:
                # try to use the first column as date if unnamed
                first_col = df.columns[0]
                if df[first_col].dtype == object or "date" in first_col.lower():
                    df.index = pd.to_datetime(df.pop(first_col))
                else:
                    continue

            df.index.name = "date"
            return df
    return None


def load_cot_dataframe(ticker: str) -> pd.DataFrame:
    """Load COT data for a ticker from disk, the data store, or a synthetic sample."""

    ticker = ticker.strip().upper() if ticker else DEFAULT_TICKER

    # 1) Try to load metrics via the DataClient if available
    if DataClient is not None and TICKER_TO_CODE:
        try:
            client = DataClient()
            # Retrieve raw COT data and reprocess to ensure feature parity
            cot_code = TICKER_TO_CODE.get(ticker)
            if cot_code:
                raw_df = client.query_cot_by_codes(cot_code)
                if raw_df is not None and not raw_df.empty:
                    raw_df = raw_df.copy()
                    date_cols = [
                        "Report_Date_as_YYYY-MM-DD",
                        "Report_Date_as_MM_DD_YYYY",
                        "Date",
                        "date",
                    ]
                    for col in date_cols:
                        if col in raw_df.columns:
                            raw_df.index = pd.to_datetime(raw_df.pop(col))
                            break
                    raw_df = cot_processor.load_and_clean_data(raw_df)
                    if not isinstance(raw_df.index, pd.DatetimeIndex):
                        raw_df.index = pd.to_datetime(raw_df.index)
                    return raw_df.sort_index()
        except Exception:
            pass

    # 2) Check for local CSV exports
    csv_df = _load_csv_if_available(ticker)
    if csv_df is not None and not csv_df.empty:
        csv_df = cot_processor.load_and_clean_data(csv_df)
        return csv_df.sort_index()

    # 3) Fall back to deterministic mock data
    return _generate_mock_cot_data(ticker)


def filter_date_range(df: pd.DataFrame, start: str | None, end: str | None) -> pd.DataFrame:
    """Clip the DataFrame to the requested date range."""

    if df.empty:
        return df

    df = df.sort_index()
    if start and end and pd.to_datetime(start) > pd.to_datetime(end):
        start, end = end, start
    if start:
        df = df[df.index >= pd.to_datetime(start)]
    if end:
        df = df[df.index <= pd.to_datetime(end)]

    return df


def split_feature_columns(columns: Iterable[str]) -> FeatureSplit:
    """Categorize feature columns into visualization groups."""

    line_keywords = ("net", "gross", "index")
    pie_keywords = ("ratio", "percent", "percentage", "share")
    bar_keywords = ("flow", "change", "momentum", "diff")
    binary_keywords = ("extreme", "regime", "indicator", "flag")

    line_cols: List[str] = []
    bar_cols: List[str] = []
    pie_cols: List[str] = []

    for col in columns:
        lower = col.lower()
        if any(keyword in lower for keyword in bar_keywords):
            bar_cols.append(col)
        elif any(keyword in lower for keyword in pie_keywords):
            pie_cols.append(col)
        elif any(keyword in lower for keyword in line_keywords):
            line_cols.append(col)
        elif any(keyword in lower for keyword in binary_keywords):
            bar_cols.append(col)
        else:
            line_cols.append(col)

    return FeatureSplit(line=line_cols, bar=bar_cols, pie=pie_cols)


def build_feature_figure(group: str, features: pd.DataFrame) -> go.Figure:
    """Create a plotly figure for a specific feature group respecting visualization rules."""

    cleaned = features.dropna(how="all")
    if cleaned.empty:
        fig = go.Figure()
        fig.update_layout(
            title=f"{group.replace('_', ' ').title()} Features",
            annotations=[
                {
                    "text": "No data available for selected range",
                    "xref": "paper",
                    "yref": "paper",
                    "x": 0.5,
                    "y": 0.5,
                    "showarrow": False,
                    "font": {"size": 14},
                }
            ],
        )
        return fig

    split = split_feature_columns(cleaned.columns)
    row_configs: List[Tuple[str, List[str]]] = []
    if split.line:
        row_configs.append(("line", split.line))
    if split.bar:
        row_configs.append(("bar", split.bar))
    if split.pie:
        row_configs.append(("pie", split.pie))

    specs = []
    titles = []
    for category, _ in row_configs:
        if category == "pie":
            specs.append([{"type": "domain"}])
            titles.append("Latest Ratio Snapshot")
        elif category == "bar":
            specs.append([{"type": "xy"}])
            titles.append("Flow & Change Metrics")
        else:
            specs.append([{"type": "xy"}])
            titles.append("Trend Metrics")

    fig = make_subplots(rows=len(row_configs), cols=1, specs=specs, subplot_titles=titles)

    for idx, (category, cols) in enumerate(row_configs, start=1):
        if category == "pie":
            latest = cleaned[cols].dropna(axis=0, how="all")
            if latest.empty:
                fig.add_annotation(
                    text="No ratio data",
                    xref="paper",
                    yref="paper",
                    x=0.5,
                    y=0.5,
                    showarrow=False,
                )
                continue
            latest_row = latest.iloc[-1]
            positive = latest_row.replace([np.inf, -np.inf], np.nan).dropna()
            if positive.empty or np.isclose(positive.abs().sum(), 0):
                positive = pd.Series([1.0], index=["No meaningful ratios"])
            fig.add_trace(
                go.Pie(labels=list(positive.index), values=positive.astype(float).tolist(), hole=0.3, name="Ratios"),
                row=idx,
                col=1,
            )
        elif category == "bar":
            for col in cols:
                fig.add_trace(
                    go.Bar(x=cleaned.index, y=cleaned[col], name=col, hovertemplate="%{x|%Y-%m-%d}: %{y:.2f}<extra></extra>"),
                    row=idx,
                    col=1,
                )
            fig.update_yaxes(title_text="Value", row=idx, col=1)
        else:
            for col in cols:
                fig.add_trace(
                    go.Scatter(
                        x=cleaned.index,
                        y=cleaned[col],
                        mode="lines",
                        name=col,
                        hovertemplate="%{x|%Y-%m-%d}: %{y:.2f}<extra></extra>",
                    ),
                    row=idx,
                    col=1,
                )
            fig.update_yaxes(title_text="Value", row=idx, col=1)

    fig.update_layout(
        height=max(350, 320 * len(row_configs)),
        showlegend=True,
        title=f"{group.replace('_', ' ').title()} Features",
        barmode="group",
        margin=dict(t=80, r=40, b=40, l=60),
    )

    return fig


def compute_feature_groups(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """Compute feature DataFrames for each COTProcessor group."""

    features: Dict[str, pd.DataFrame] = {}
    for group in FEATURE_GROUPS:
        group_features = cot_processor.calculate_enhanced_cot_features(
            df, selected_cot_features=[group]
        )
        features[group] = group_features
    return features


def create_layout(app: Dash, default_df: pd.DataFrame) -> html.Div:
    start_date = default_df.index.min()
    end_date = default_df.index.max()

    return html.Div(
        [
            html.H1("COT Feature Dashboard"),
            html.Div(
                [
                    html.Label("Ticker"),
                    dcc.Input(
                        id="ticker-input",
                        type="text",
                        value=DEFAULT_TICKER,
                        placeholder="Enter ticker (e.g., CL_F)",
                        debounce=True,
                    ),
                    html.Label("Analysis Range", style={"marginLeft": "1.5rem"}),
                    dcc.DatePickerRange(
                        id="date-range",
                        min_date_allowed=start_date,
                        max_date_allowed=end_date,
                        start_date=start_date,
                        end_date=end_date,
                        display_format="YYYY-MM-DD",
                    ),
                ],
                className="controls",
                style={
                    "display": "flex",
                    "gap": "1rem",
                    "alignItems": "center",
                    "flexWrap": "wrap",
                },
            ),
            html.Hr(),
            dcc.Loading(id="loading", type="default", children=html.Div(id="graphs-container")),
        ]
    )


def build_dashboard_app() -> Dash:
    default_df = load_cot_dataframe(DEFAULT_TICKER)
    app = Dash(__name__)
    app.title = "COT Feature Dashboard"
    app.layout = create_layout(app, default_df)

    @app.callback(
        Output("graphs-container", "children"),
        Input("ticker-input", "value"),
        Input("date-range", "start_date"),
        Input("date-range", "end_date"),
    )
    def update_graphs(ticker_value: str, start_date: str | None, end_date: str | None):
        ticker = ticker_value.strip().upper() if ticker_value else DEFAULT_TICKER
        df = load_cot_dataframe(ticker)
        filtered = filter_date_range(df, start_date, end_date)
        if filtered.empty:
            return html.Div(
                "No data available for the selected inputs.",
                style={"padding": "1rem", "fontWeight": "600"},
            )

        feature_groups = compute_feature_groups(filtered)
        children = []
        for group, feature_df in feature_groups.items():
            fig = build_feature_figure(group, feature_df)
            children.append(
                html.Div(
                    [
                        html.H3(group.replace("_", " ").title()),
                        dcc.Graph(figure=fig, id=f"{group}-graph"),
                    ],
                    style={"marginBottom": "2rem"},
                )
            )
        return children

    return app


def main() -> None:
    app = build_dashboard_app()
    app.run_server(debug=True)


if __name__ == "__main__":
    main()

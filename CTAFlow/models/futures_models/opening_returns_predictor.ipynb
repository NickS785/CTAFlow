{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Returns Prediction with IntradayMomentumLight\n",
    "\n",
    "This notebook demonstrates how to use `IntradayMomentumLight` (which inherits from `CTALight`) to predict opening period returns using:\n",
    "\n",
    "1. **Short-term daily momentum features** (1d, 5d, 10d, 20d) - properly lagged to avoid lookahead bias\n",
    "2. **HAR-style realized volatility features** for 1-day ahead forecasts\n",
    "3. **Opening range volatility measures** - first 60 minutes of the session\n",
    "\n",
    "**Target**: Returns during the opening period (first 60 minutes of session)\n",
    "\n",
    "**Model**: LightGBM regressor (via CTALight base class) with built-in `.fit()`, `.fit_with_grid_search()`, and `.evaluate()` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import time, timedelta\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directories to path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from CTAFlow.models.intraday_momentum import IntradayMomentumLight\n",
    "from CTAFlow.config import INTRADAY_DATA_PATH\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"✓ Imports successful\")\n",
    "print(f\"✓ Data path: {INTRADAY_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opening_returns(\n",
    "    intraday_df: pd.DataFrame,\n",
    "    session_open: time = time(8, 30),\n",
    "    opening_window: timedelta = timedelta(minutes=60),\n",
    "    price_col: str = \"Close\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate daily returns during the opening period.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    intraday_df : pd.DataFrame\n",
    "        Intraday OHLCV data with DatetimeIndex\n",
    "    session_open : time\n",
    "        Session start time (default 8:30 AM)\n",
    "    opening_window : timedelta\n",
    "        Length of opening period (default 60 minutes)\n",
    "    price_col : str\n",
    "        Price column name\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Daily opening period returns (log returns from open to open+window)\n",
    "    \"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "    \n",
    "    # Create working dataframe\n",
    "    work_df = pd.DataFrame({'price': intraday_df[price_col]})\n",
    "    work_df['date'] = work_df.index.normalize()\n",
    "    \n",
    "    # Calculate session times\n",
    "    session_open_offset = pd.Timedelta(hours=session_open.hour, minutes=session_open.minute)\n",
    "    work_df['session_start'] = work_df['date'] + session_open_offset\n",
    "    work_df['session_end'] = work_df['session_start'] + opening_window\n",
    "    \n",
    "    # Get opening and closing prices\n",
    "    opening_mask = work_df.index >= work_df['session_start']\n",
    "    opening_data = work_df[opening_mask].groupby('date')['price'].first()\n",
    "    \n",
    "    closing_mask = (work_df.index >= work_df['session_start']) & (work_df.index < work_df['session_end'])\n",
    "    closing_data = work_df[closing_mask].groupby('date')['price'].last()\n",
    "    \n",
    "    # Calculate log returns\n",
    "    opening_returns = np.log(closing_data / opening_data)\n",
    "    \n",
    "    return opening_returns\n",
    "\n",
    "\n",
    "def prepare_daily_data(intraday_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create daily OHLC data from intraday bars.\"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "    \n",
    "    daily = intraday_df.resample('1D').agg({\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    }).dropna()\n",
    "    \n",
    "    return daily\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load intraday data for a single ticker from CSV. Using the same file path structure as `gather_tickers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"CL\"  # Crude Oil futures\n",
    "\n",
    "# Load intraday data from CSV\n",
    "csv_path = INTRADAY_DATA_PATH / f\"{ticker}_intraday.csv\"\n",
    "print(f\"Loading {ticker} from {csv_path}\")\n",
    "\n",
    "intraday_data = pd.read_csv(csv_path, parse_dates=['timestamp'])\n",
    "intraday_data.set_index('timestamp', inplace=True)\n",
    "intraday_data.sort_index(inplace=True)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(intraday_data):,} bars\")\n",
    "print(f\"✓ Date range: {intraday_data.index[0].date()} to {intraday_data.index[-1].date()}\")\n",
    "print(f\"\\nData preview:\")\n",
    "intraday_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize IntradayMomentumLight Model\n",
    "\n",
    "`IntradayMomentumLight` inherits from `CTALight`, which provides built-in LightGBM functionality:\n",
    "- `.fit()` - Train the model with early stopping\n",
    "- `.fit_with_grid_search()` - Hyperparameter tuning with cross-validation\n",
    "- `.evaluate()` - Compute metrics on test set\n",
    "- `.predict()` - Generate predictions\n",
    "- `.get_feature_importance()` - Extract feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    price_col=\"Close\"\n",
    ")\n",
    "\n",
    "print(\"✓ Model initialized (inherits LightGBM functionality from CTALight)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = prepare_daily_data(intraday_data)\n",
    "print(f\"✓ Daily data: {len(daily_df)} days\")\n",
    "print(f\"\\nDaily OHLCV preview:\")\n",
    "daily_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Feature Set\n",
    "\n",
    "We'll use three types of features:\n",
    "1. **Daily Momentum** - Short-term price trends (1d, 5d, 10d, 20d)\n",
    "2. **HAR Volatility** - Multi-horizon realized volatility (1d, 5d, 22d)\n",
    "3. **Opening Range Volatility** - First 60 minutes volatility measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training_data\n",
    "model.training_data = pd.DataFrame(index=daily_df.index)\n",
    "\n",
    "# 1. Daily momentum features (lagged by 1 day)\n",
    "print(\"Adding daily momentum features...\")\n",
    "momentum_feats = model.add_daily_momentum_features(\n",
    "    daily_df,\n",
    "    lookbacks=(1, 5, 10, 20)\n",
    ")\n",
    "print(f\"  Features: {list(momentum_feats.columns)}\")\n",
    "\n",
    "# 2. HAR volatility features\n",
    "print(\"\\nAdding HAR volatility features...\")\n",
    "har_feats = model.har_volatility_features(\n",
    "    intraday_df=intraday_data,\n",
    "    horizons=(1, 5, 22)\n",
    ")\n",
    "print(f\"  Features: {list(har_feats.columns)}\")\n",
    "\n",
    "# 3. Opening range volatility\n",
    "print(\"\\nAdding opening range volatility...\")\n",
    "opening_vol = model.opening_range_volatility(\n",
    "    intraday_df=intraday_data,\n",
    "    period_length=timedelta(minutes=60)\n",
    ")\n",
    "print(f\"  Features: {list(opening_vol.columns)}\")\n",
    "\n",
    "# Combine all features\n",
    "model.training_data = pd.concat([momentum_feats, har_feats, opening_vol], axis=1).dropna()\n",
    "print(f\"\\n✓ Combined features shape: {model.training_data.shape}\")\n",
    "print(f\"✓ Feature names tracked: {model.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the feature matrix\n",
    "print(\"Feature matrix preview:\")\n",
    "model.training_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Target Variable\n",
    "\n",
    "Target is the log return during the opening period (first 60 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = calculate_opening_returns(intraday_data)\n",
    "\n",
    "print(f\"✓ Target shape: {len(target)}\")\n",
    "print(f\"✓ Target mean: {target.mean():.6f}\")\n",
    "print(f\"✓ Target std: {target.std():.6f}\")\n",
    "print(f\"✓ Target min: {target.min():.6f}\")\n",
    "print(f\"✓ Target max: {target.max():.6f}\")\n",
    "\n",
    "# Plot target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(target, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(target.mean(), color='red', linestyle='--', label=f'Mean: {target.mean():.4f}')\n",
    "axes[0].set_xlabel('Opening Returns (log)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Opening Period Returns')\n",
    "axes[0].legend()\n",
    "\n",
    "# Time series\n",
    "axes[1].plot(target.index, target, alpha=0.6, linewidth=0.8)\n",
    "axes[1].axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Opening Returns (log)')\n",
    "axes[1].set_title('Opening Period Returns Over Time')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_index = model.training_data.index.intersection(target.index)\n",
    "X = model.training_data.loc[common_index]\n",
    "y = target.loc[common_index]\n",
    "\n",
    "print(f\"✓ Final dataset: {len(X)} samples, {X.shape[1]} features\")\n",
    "print(f\"✓ Date range: {X.index[0].date()} to {X.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split (Temporal)\n",
    "\n",
    "Using 80/20 temporal split to avoid lookahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "split_idx = int(len(X) * (1 - test_size))\n",
    "\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples ({X_train.index[0].date()} to {X_train.index[-1].date()})\")\n",
    "print(f\"Test:  {len(X_test)} samples ({X_test.index[0].date()} to {X_test.index[-1].date()})\")\n",
    "\n",
    "# Create validation set for early stopping (from training set)\n",
    "val_size = int(len(X_train) * 0.2)\n",
    "X_val = X_train.iloc[-val_size:]\n",
    "y_val = y_train.iloc[-val_size:]\n",
    "X_train_fit = X_train.iloc[:-val_size]\n",
    "y_train_fit = y_train.iloc[:-val_size]\n",
    "\n",
    "print(f\"\\nFor training:\")\n",
    "print(f\"  Training: {len(X_train_fit)} samples\")\n",
    "print(f\"  Validation: {len(X_val)} samples (for early stopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightGBM Model\n",
    "\n",
    "Using the built-in `.fit()` method from CTALight base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training LightGBM model (via CTALight.fit())...\\n\")\n",
    "\n",
    "model.fit(\n",
    "    X_train_fit,\n",
    "    y_train_fit,\n",
    "    eval_set=(X_val, y_val),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Set Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:                    {test_metrics['mse']:.6f}\")\n",
    "print(f\"RMSE:                   {test_metrics['rmse']:.6f}\")\n",
    "print(f\"MAE:                    {test_metrics['mae']:.6f}\")\n",
    "print(f\"R²:                     {test_metrics['r2']:.4f}\")\n",
    "print(f\"Directional Accuracy:   {test_metrics['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions vs Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Scatter plot\n",
    "axes[0, 0].scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Actual Returns')\n",
    "axes[0, 0].set_ylabel('Predicted Returns')\n",
    "axes[0, 0].set_title(f'Predictions vs Actuals (R² = {test_metrics[\"r2\"]:.4f})')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Time series\n",
    "axes[0, 1].plot(y_test.index, y_test.values, label='Actual', alpha=0.7, linewidth=1)\n",
    "axes[0, 1].plot(y_test.index, y_pred, label='Predicted', alpha=0.7, linewidth=1)\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Returns')\n",
    "axes[0, 1].set_title('Actual vs Predicted Returns Over Time')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals\n",
    "residuals = y_test - y_pred\n",
    "axes[1, 0].scatter(y_pred, residuals, alpha=0.5, s=20)\n",
    "axes[1, 0].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Predicted Returns')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Residual Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals distribution\n",
    "axes[1, 1].hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "axes[1, 1].axvline(residuals.mean(), color='blue', linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {residuals.mean():.4f}')\n",
    "axes[1, 1].set_xlabel('Residuals')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Residuals')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top features\n",
    "top_features = model.get_feature_importance(importance_type='gain', top_n=10)\n",
    "\n",
    "print(\"Top 10 Features by Gain:\")\n",
    "print(\"=\" * 50)\n",
    "for feat, importance in top_features.items():\n",
    "    print(f\"{feat:25s}: {importance:.1f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "features = list(top_features.keys())\n",
    "importances = list(top_features.values())\n",
    "\n",
    "ax.barh(features, importances, color='steelblue', alpha=0.8)\n",
    "ax.set_xlabel('Importance (Gain)')\n",
    "ax.set_title('Top 10 Feature Importances')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Hyperparameter Tuning\n",
    "\n",
    "Demonstrating the `.fit_with_grid_search()` method for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running grid search for hyperparameter tuning...\\n\")\n",
    "\n",
    "# Reinitialize model for grid search\n",
    "model_gs = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    tz=\"America/Chicago\"\n",
    ")\n",
    "\n",
    "# Rebuild features (same as before)\n",
    "model_gs.training_data = pd.DataFrame(index=daily_df.index)\n",
    "momentum_feats_gs = model_gs.add_daily_momentum_features(daily_df, lookbacks=(1, 5, 10, 20))\n",
    "har_feats_gs = model_gs.har_volatility_features(intraday_df=intraday_data, horizons=(1, 5, 22))\n",
    "opening_vol_gs = model_gs.opening_range_volatility(intraday_df=intraday_data, period_length=timedelta(minutes=60))\n",
    "model_gs.training_data = pd.concat([momentum_feats_gs, har_feats_gs, opening_vol_gs], axis=1).dropna()\n",
    "\n",
    "# Use same target\n",
    "common_index_gs = model_gs.training_data.index.intersection(target.index)\n",
    "X_gs = model_gs.training_data.loc[common_index_gs]\n",
    "y_gs = target.loc[common_index_gs]\n",
    "\n",
    "# Split (80/20 for grid search)\n",
    "split_idx = int(len(X_gs) * 0.8)\n",
    "X_train_gs, X_test_gs = X_gs.iloc[:split_idx], X_gs.iloc[split_idx:]\n",
    "y_train_gs, y_test_gs = y_gs.iloc[:split_idx], y_gs.iloc[split_idx:]\n",
    "val_size = int(len(X_train_gs) * 0.2)\n",
    "X_val_gs = X_train_gs.iloc[-val_size:]\n",
    "y_val_gs = y_train_gs.iloc[-val_size:]\n",
    "X_train_fit_gs = X_train_gs.iloc[:-val_size]\n",
    "y_train_fit_gs = y_train_gs.iloc[:-val_size]\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'learning_rate': [0.03, 0.07],\n",
    "    'feature_fraction': [0.7, 0.9]\n",
    "}\n",
    "\n",
    "print(f\"Parameter grid: {param_grid}\")\n",
    "print(f\"Total combinations: {np.prod([len(v) for v in param_grid.values()])}\\n\")\n",
    "\n",
    "# Run grid search\n",
    "grid_results = model_gs.fit_with_grid_search(\n",
    "    X_train_fit_gs,\n",
    "    y_train_fit_gs,\n",
    "    param_grid=param_grid,\n",
    "    eval_set=(X_val_gs, y_val_gs),\n",
    "    cv_folds=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Grid search complete!\")\n",
    "print(f\"\\nBest parameters: {grid_results['best_params']}\")\n",
    "print(f\"Best CV score: {grid_results['best_score']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate grid search model on test set\n",
    "gs_metrics = model_gs.evaluate(X_test_gs, y_test_gs)\n",
    "\n",
    "print(\"Grid Search Model - Test Set Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:                    {gs_metrics['mse']:.6f}\")\n",
    "print(f\"RMSE:                   {gs_metrics['rmse']:.6f}\")\n",
    "print(f\"MAE:                    {gs_metrics['mae']:.6f}\")\n",
    "print(f\"R²:                     {gs_metrics['r2']:.4f}\")\n",
    "print(f\"Directional Accuracy:   {gs_metrics['directional_accuracy']:.2%}\")\n",
    "\n",
    "# Compare with baseline model\n",
    "print(\"\\nComparison with Baseline:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Baseline R²:      {test_metrics['r2']:.4f}\")\n",
    "print(f\"Grid Search R²:   {gs_metrics['r2']:.4f}\")\n",
    "print(f\"Improvement:      {(gs_metrics['r2'] - test_metrics['r2']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ Loading single ticker intraday data\n",
    "2. ✓ Building features with `IntradayMomentumLight` methods:\n",
    "   - Daily momentum (lagged)\n",
    "   - HAR volatility\n",
    "   - Opening range volatility\n",
    "3. ✓ Training LightGBM model using `.fit()` from `CTALight`\n",
    "4. ✓ Evaluating model performance with built-in metrics\n",
    "5. ✓ Visualizing predictions and feature importance\n",
    "6. ✓ Hyperparameter tuning with `.fit_with_grid_search()`\n",
    "\n",
    "**Key Takeaways:**\n",
    "- `IntradayMomentumLight` inherits LightGBM functionality from `CTALight`\n",
    "- Features are automatically tracked via `._add_feature()` method\n",
    "- Proper lagging prevents lookahead bias\n",
    "- Opening returns are predictable using momentum and volatility features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

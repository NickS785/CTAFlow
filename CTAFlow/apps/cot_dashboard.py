"""Dash application for exploring COT features generated by :class:`COTProcessor`.

The dashboard exposes controls for selecting a ticker and analysis date range and
visualizes each feature group returned by :func:`CTAFlow.features.signals_processing.COTProcessor.calculate_enhanced_cot_features`.

Usage
-----
Run the app with::

    python -m CTAFlow.apps.cot_dashboard

The app will attempt to load preprocessed COT metrics for the requested ticker
from the local CTAFlow data store. When metrics are not available a synthetic
sample dataset is generated so the visualizations remain interactive.
"""

from __future__ import annotations

from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import numpy as np
import pandas as pd
from dash import Dash, Input, Output, dcc, html
from plotly.subplots import make_subplots
import plotly.graph_objects as go

from CTAFlow.features.signals_processing import COTProcessor

try:  # Optional dependency for real COT metrics if the data store exists
    from CTAFlow.data import DataClient  # type: ignore
except Exception:  # pragma: no cover - the dashboard works without the data store
    DataClient = None  # type: ignore

try:  # Optional mapping of tickers to COT codes for DataClient fallback
    from CTAFlow.config import TICKER_TO_CODE  # type: ignore
except Exception:  # pragma: no cover - config may be unavailable in minimal installs
    TICKER_TO_CODE = {}  # type: ignore


# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------

FEATURE_GROUPS: Tuple[str, ...] = (
    "positioning",
    "flows",
    "extremes",
    "market_structure",
    "interactions",
    "spreads",
)
DEFAULT_TICKER = "CL_F"
DEFAULT_PERIODS = 160  # roughly three years of weekly observations

cot_processor = COTProcessor()


@dataclass
class FeatureSplit:
    """Container describing how feature columns should be visualized."""

    line: List[str]
    bar: List[str]
    pie: List[str]

    def is_empty(self) -> bool:
        return not (self.line or self.bar or self.pie)


def _get_data_directory() -> Path:
    return Path(__file__).resolve().parents[1] / "data"


@lru_cache(maxsize=16)
def _generate_mock_cot_data(ticker: str, periods: int = DEFAULT_PERIODS) -> pd.DataFrame:
    """Generate a deterministic synthetic COT dataset for demonstration purposes."""

    rng = np.random.default_rng(abs(hash(ticker)) % (2**32))
    index = pd.date_range(end=pd.Timestamp.today().normalize(), periods=periods, freq="W-FRI")

    # Create smooth baseline series to mimic COT style positioning data
    market_participation = np.clip(200_000 + np.cumsum(rng.normal(0, 4_000, periods)), 50_000, None)
    commercial_longs = np.clip(70_000 + np.cumsum(rng.normal(0, 2_000, periods)), 20_000, None)
    commercial_shorts = np.clip(60_000 + np.cumsum(rng.normal(0, 2_000, periods)), 15_000, None)
    mm_longs = np.clip(55_000 + np.cumsum(rng.normal(0, 2_500, periods)), 10_000, None)
    mm_shorts = np.clip(48_000 + np.cumsum(rng.normal(0, 2_500, periods)), 10_000, None)
    swap_longs = np.clip(25_000 + np.cumsum(rng.normal(0, 1_200, periods)), 5_000, None)
    swap_shorts = np.clip(20_000 + np.cumsum(rng.normal(0, 1_200, periods)), 5_000, None)
    other_longs = np.clip(15_000 + np.cumsum(rng.normal(0, 900, periods)), 2_000, None)
    other_shorts = np.clip(10_000 + np.cumsum(rng.normal(0, 900, periods)), 2_000, None)
    spreads = np.clip(5_000 + np.cumsum(rng.normal(0, 500, periods)), 1_000, None)
    non_reportable_longs = np.clip(12_000 + np.cumsum(rng.normal(0, 800, periods)), 1_000, None)
    non_reportable_shorts = np.clip(11_000 + np.cumsum(rng.normal(0, 800, periods)), 1_000, None)

    total_reportable_longs = mm_longs + commercial_longs + swap_longs + other_longs
    total_reportable_shorts = mm_shorts + commercial_shorts + swap_shorts + other_shorts

    df = pd.DataFrame(
        {
            "market_participation": market_participation,
            "producer_merchant_processor_user_longs": commercial_longs,
            "producer_merchant_processor_user_shorts": commercial_shorts,
            "money_manager_longs": mm_longs,
            "money_manager_shorts": mm_shorts,
            "money_manager_spreads": spreads,
            "swap_dealer_longs": swap_longs,
            "swap_dealer_shorts": swap_shorts,
            "other_reportable_longs": other_longs,
            "other_reportable_shorts": other_shorts,
            "total_reportable_longs": total_reportable_longs,
            "total_reportable_shorts": total_reportable_shorts,
            "non_reportable_longs": non_reportable_longs,
            "non_reportable_shorts": non_reportable_shorts,
        },
        index=index,
    )

    return df.sort_index()


def _load_csv_if_available(ticker: str) -> pd.DataFrame | None:
    """Attempt to load COT data from a CSV file in the project data directory."""

    data_dir = _get_data_directory()
    candidates = [
        data_dir / f"{ticker}.csv",
        data_dir / f"{ticker.lower()}.csv",
        data_dir / f"{ticker.upper()}_cot.csv",
        data_dir / f"{ticker.lower()}_cot.csv",
    ]

    for path in candidates:
        if path.exists():
            df = pd.read_csv(path)
            df = df.copy()
            if "date" in df.columns:
                df.index = pd.to_datetime(df.pop("date"))
            elif "Date" in df.columns:
                df.index = pd.to_datetime(df.pop("Date"))
            elif "Report_Date_as_YYYY-MM-DD" in df.columns:
                df.index = pd.to_datetime(df.pop("Report_Date_as_YYYY-MM-DD"))
            else:
                # try to use the first column as date if unnamed
                first_col = df.columns[0]
                if df[first_col].dtype == object or "date" in first_col.lower():
                    df.index = pd.to_datetime(df.pop(first_col))
                else:
                    continue

            df.index.name = "date"
            return df
    return None


def load_cot_dataframe(ticker: str) -> pd.DataFrame:
    """Load COT data for a ticker from disk, the data store, or a synthetic sample."""

    ticker = ticker.strip().upper() if ticker else DEFAULT_TICKER

    # 1) Try to load metrics via the DataClient if available
    if DataClient is not None and TICKER_TO_CODE:
        try:
            client = DataClient()
            # Retrieve raw COT data and reprocess to ensure feature parity
            cot_code = TICKER_TO_CODE.get(ticker)
            if cot_code:
                raw_df = client.query_cot_by_codes(cot_code)
                if raw_df is not None and not raw_df.empty:
                    # Use COTProcessor's built-in cleaning first
                    raw_df = cot_processor.load_and_clean_data(raw_df)

                    # Handle date conversion with error handling for mixed formats
                    if not isinstance(raw_df.index, pd.DatetimeIndex):
                        date_cols = [
                            "Report_Date_as_YYYY-MM-DD",
                            "Report_Date_as_MM_DD_YYYY",
                            "Date",
                            "date",
                        ]
                        for col in date_cols:
                            if col in raw_df.columns:
                                # Handle mixed date formats and 'None' strings
                                raw_df.index = pd.to_datetime(raw_df[col], errors='coerce')
                                # Remove rows with invalid dates
                                raw_df = raw_df[raw_df.index.notna()]
                                break
                    return raw_df.sort_index()
        except Exception:
            pass

    # 2) Check for local CSV exports
    csv_df = _load_csv_if_available(ticker)
    if csv_df is not None and not csv_df.empty:
        csv_df = cot_processor.load_and_clean_data(csv_df)
        return csv_df.sort_index()

    # 3) Fall back to deterministic mock data
    return _generate_mock_cot_data(ticker)


def filter_date_range(df: pd.DataFrame, start: str | None, end: str | None) -> pd.DataFrame:
    """Clip the DataFrame to the requested date range."""

    if df.empty:
        return df

    df = df.sort_index()
    if start and end and pd.to_datetime(start) > pd.to_datetime(end):
        start, end = end, start
    if start:
        df = df[df.index >= pd.to_datetime(start)]
    if end:
        df = df[df.index <= pd.to_datetime(end)]

    return df


def split_feature_columns(columns: Iterable[str]) -> FeatureSplit:
    """Categorize feature columns into visualization groups."""

    line_keywords = ("net", "gross", "index", "ratio", "percent", "percentage", "share")
    bar_keywords = ("flow", "change", "momentum", "diff")
    binary_keywords = ("extreme", "regime", "indicator", "flag")

    line_cols: List[str] = []
    bar_cols: List[str] = []
    pie_cols: List[str] = []

    for col in columns:
        lower = col.lower()
        if any(keyword in lower for keyword in bar_keywords):
            bar_cols.append(col)
        elif any(keyword in lower for keyword in line_keywords):
            line_cols.append(col)
        elif any(keyword in lower for keyword in binary_keywords):
            bar_cols.append(col)
        else:
            line_cols.append(col)

    return FeatureSplit(line=line_cols, bar=bar_cols, pie=pie_cols)


def build_cot_index_figure(features: pd.DataFrame) -> go.Figure:
    """Create a specialized figure for COT index data with extreme threshold lines."""

    # Filter to only the main positioning indices
    main_indices = [
        'mm_net_position_cot_index',
        'mm_long_ratio_cot_index',
        'commercial_net_cot_index',
        'commercial_long_ratio_cot_index'
    ]

    # Find available COT index columns, filtered to main ones
    available_cols = [col for col in main_indices if col in features.columns]

    if not available_cols:
        fig = go.Figure()
        fig.update_layout(
            title="COT Index Analysis",
            annotations=[
                {
                    "text": "No main COT index data available",
                    "xref": "paper",
                    "yref": "paper",
                    "x": 0.5,
                    "y": 0.5,
                    "showarrow": False,
                    "font": {"size": 14},
                }
            ],
        )
        return fig

    fig = go.Figure()

    # Color scheme for the 4 main indices
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # blue, orange, green, red

    # Calculate data range for better y-axis scaling
    all_values = []

    # Add COT index lines
    for idx, col in enumerate(available_cols):
        clean_data = features[col].dropna()
        if not clean_data.empty:
            all_values.extend(clean_data.values)

            # Clean up column name for legend
            name_mapping = {
                'mm_net_position_cot_index': 'MM Net Position',
                'mm_long_ratio_cot_index': 'MM Long Ratio',
                'commercial_net_cot_index': 'Commercial Net',
                'commercial_long_ratio_cot_index': 'Commercial Long Ratio'
            }
            display_name = name_mapping.get(col, col.replace('_cot_index', '').replace('_', ' ').title())

            fig.add_trace(
                go.Scatter(
                    x=clean_data.index,
                    y=clean_data.values,
                    mode="lines",
                    name=display_name,
                    line=dict(width=2.5, color=colors[idx % len(colors)]),
                    hovertemplate="%{x|%Y-%m-%d}<br>%{fullData.name}: %{y:.1f}<extra></extra>",
                )
            )

    # Calculate better y-axis range with some padding
    if all_values:
        min_val = min(all_values)
        max_val = max(all_values)
        padding = (max_val - min_val) * 0.1
        y_min = max(0, min_val - padding)
        y_max = min(100, max_val + padding)

        # Ensure we show extreme thresholds if data is near them
        if min_val <= 25:
            y_min = 0
        if max_val >= 75:
            y_max = 100
    else:
        y_min, y_max = 0, 100

    # Add extreme threshold lines
    fig.add_hline(
        y=85,
        line_dash="dash",
        line_color="red",
        line_width=1.5,
        annotation_text="Extreme Long (85)",
        annotation_position="right"
    )
    fig.add_hline(
        y=15,
        line_dash="dash",
        line_color="red",
        line_width=1.5,
        annotation_text="Extreme Short (15)",
        annotation_position="right"
    )

    # Add shaded regions for extreme zones (only if they're in view)
    if y_max > 80:
        fig.add_hrect(
            y0=85, y1=100,
            fillcolor="red", opacity=0.1,
            line_width=0
        )
    if y_min < 20:
        fig.add_hrect(
            y0=0, y1=15,
            fillcolor="red", opacity=0.1,
            line_width=0
        )

    fig.update_layout(
        title="COT Index - Key Positioning Metrics",
        xaxis_title="Date",
        yaxis_title="COT Index",
        yaxis=dict(range=[y_min, y_max]),
        height=500,
        showlegend=True,
        margin=dict(t=80, r=40, b=40, l=60),
        hovermode='x unified',
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="left",
            x=0.01
        )
    )

    return fig


def build_feature_figure(group: str, features: pd.DataFrame) -> go.Figure:
    """Create a plotly figure for a specific feature group respecting visualization rules."""

    # Special handling for interactions group to show COT index
    if group == "interactions":
        return build_cot_index_figure(features)

    cleaned = features.dropna(how="all")
    if cleaned.empty:
        fig = go.Figure()
        fig.update_layout(
            title=f"{group.replace('_', ' ').title()} Features",
            annotations=[
                {
                    "text": "No data available for selected range",
                    "xref": "paper",
                    "yref": "paper",
                    "x": 0.5,
                    "y": 0.5,
                    "showarrow": False,
                    "font": {"size": 14},
                }
            ],
        )
        return fig

    split = split_feature_columns(cleaned.columns)
    row_configs: List[Tuple[str, List[str]]] = []
    if split.line:
        row_configs.append(("line", split.line))
    if split.bar:
        row_configs.append(("bar", split.bar))
    if split.pie:
        row_configs.append(("pie", split.pie))

    specs = []
    titles = []
    for category, _ in row_configs:
        if category == "pie":
            specs.append([{"type": "domain"}])
            titles.append("Latest Ratio Snapshot")
        elif category == "bar":
            specs.append([{"type": "xy"}])
            titles.append("Flow & Change Metrics")
        else:
            specs.append([{"type": "xy"}])
            titles.append("Trend Metrics")

    fig = make_subplots(rows=len(row_configs), cols=1, specs=specs, subplot_titles=titles)

    for idx, (category, cols) in enumerate(row_configs, start=1):
        if category == "pie":
            latest = cleaned[cols].dropna(axis=0, how="all")
            if latest.empty:
                fig.add_annotation(
                    text="No ratio data",
                    xref="paper",
                    yref="paper",
                    x=0.5,
                    y=0.5,
                    showarrow=False,
                )
                continue
            latest_row = latest.iloc[-1]
            positive = latest_row.replace([np.inf, -np.inf], np.nan).dropna()
            if positive.empty or np.isclose(positive.abs().sum(), 0):
                positive = pd.Series([1.0], index=["No meaningful ratios"])
            fig.add_trace(
                go.Pie(labels=list(positive.index), values=positive.astype(float).tolist(), hole=0.3, name="Ratios"),
                row=idx,
                col=1,
            )
        elif category == "bar":
            for col in cols:
                fig.add_trace(
                    go.Bar(x=cleaned.index, y=cleaned[col], name=col, hovertemplate="%{x|%Y-%m-%d}: %{y:.2f}<extra></extra>"),
                    row=idx,
                    col=1,
                )
            fig.update_yaxes(title_text="Value", row=idx, col=1)
        else:
            for col in cols:
                fig.add_trace(
                    go.Scatter(
                        x=cleaned.index,
                        y=cleaned[col],
                        mode="lines",
                        name=col,
                        hovertemplate="%{x|%Y-%m-%d}: %{y:.2f}<extra></extra>",
                    ),
                    row=idx,
                    col=1,
                )
            fig.update_yaxes(title_text="Value", row=idx, col=1)

    fig.update_layout(
        height=max(350, 320 * len(row_configs)),
        showlegend=True,
        title=f"{group.replace('_', ' ').title()} Features",
        barmode="group",
        margin=dict(t=80, r=40, b=40, l=60),
    )

    return fig


def compute_feature_groups(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """Compute feature DataFrames for each COTProcessor group."""

    features: Dict[str, pd.DataFrame] = {}
    for group in FEATURE_GROUPS:
        # For interactions group, compute positioning first, then extremes to get COT index data
        if group == "interactions":
            combined_features = cot_processor.calculate_enhanced_cot_features(
                df, selected_cot_features=["positioning", "interactions", "extremes"]
            )
            features[group] = combined_features
        # For extremes group, also compute positioning first since extremes depends on it
        elif group == "extremes":
            combined_features = cot_processor.calculate_enhanced_cot_features(
                df, selected_cot_features=["positioning", "extremes"]
            )
            features[group] = combined_features
        else:
            group_features = cot_processor.calculate_enhanced_cot_features(
                df, selected_cot_features=[group]
            )
            features[group] = group_features
    return features


def create_layout(app: Dash, default_df: pd.DataFrame) -> html.Div:
    start_date = default_df.index.min()
    end_date = default_df.index.max()

    return html.Div(
        [
            html.H1("COT Feature Dashboard"),
            html.Div(
                [
                    html.Label("Ticker"),
                    dcc.Input(
                        id="ticker-input",
                        type="text",
                        value=DEFAULT_TICKER,
                        placeholder="Enter ticker (e.g., CL_F)",
                        debounce=True,
                    ),
                    html.Label("Analysis Range", style={"marginLeft": "1.5rem"}),
                    dcc.DatePickerRange(
                        id="date-range",
                        min_date_allowed=start_date,
                        max_date_allowed=end_date,
                        start_date=start_date,
                        end_date=end_date,
                        display_format="YYYY-MM-DD",
                    ),
                ],
                className="controls",
                style={
                    "display": "flex",
                    "gap": "1rem",
                    "alignItems": "center",
                    "flexWrap": "wrap",
                },
            ),
            html.Hr(),
            dcc.Loading(id="loading", type="default", children=html.Div(id="graphs-container")),
        ]
    )


def build_dashboard_app() -> Dash:
    default_df = load_cot_dataframe(DEFAULT_TICKER)
    app = Dash(__name__)
    app.title = "COT Feature Dashboard"
    app.layout = create_layout(app, default_df)

    @app.callback(
        Output("graphs-container", "children"),
        Input("ticker-input", "value"),
        Input("date-range", "start_date"),
        Input("date-range", "end_date"),
    )
    def update_graphs(ticker_value: str, start_date: str | None, end_date: str | None):
        ticker = ticker_value.strip().upper() if ticker_value else DEFAULT_TICKER
        df = load_cot_dataframe(ticker)
        filtered = filter_date_range(df, start_date, end_date)
        if filtered.empty:
            return html.Div(
                "No data available for the selected inputs.",
                style={"padding": "1rem", "fontWeight": "600"},
            )

        feature_groups = compute_feature_groups(filtered)
        children = []
        for group, feature_df in feature_groups.items():
            fig = build_feature_figure(group, feature_df)
            children.append(
                html.Div(
                    [
                        html.H3(group.replace("_", " ").title()),
                        dcc.Graph(figure=fig, id=f"{group}-graph"),
                    ],
                    style={"marginBottom": "2rem"},
                )
            )
        return children

    return app


def main() -> None:
    app = build_dashboard_app()
    app.run(debug=True)


if __name__ == "__main__":
    main()

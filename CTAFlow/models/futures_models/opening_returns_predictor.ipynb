{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title\n",
    "!git clone https://github.com/NickS785/CTAFlow -b v2\n",
    "\n",
    "!pip install -e CTAFlow\n",
    "!git clone https://github.com/NickS785/SierraPy\n",
    "!pip install -e SierraPy\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append( \"//content/SierraPy\")\n",
    "sys.path.append (\"//content/CTAFlow/CTAFlow\")\n",
    "from SierraPy import sierrapy"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Opening Returns Prediction with IntradayMomentumLight\n\nThis notebook demonstrates:\n1. **Regression Models** - LightGBM (baseline & tuned), XGBoost, Random Forest\n2. **Classification Models** - Binary and multiclass LightGBM classifiers\n3. **Model Comparison** - Compare performance across different algorithms\n\n**Features Used:**\n- Short-term daily momentum (1d, 5d, 10d, 20d) - properly lagged\n- HAR-style realized volatility (1d, 5d, 22d)\n- Opening range volatility (first 60 minutes)\n- Previous high/low features\n\n**Target**: Returns during the opening period (first 60 minutes of session)\n**Important**: Uses `model.target_data` to ensure consistency and avoid lookahead bias"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from __future__ import annotation\nimport sys\nfrom pathlib import Path\nfrom datetime import time, timedelta\nfrom typing import Dict\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Add parent directories to path\nproject_root = Path.cwd().parent.parent.parent\nsys.path.insert(0, str(project_root))\n\nfrom CTAFlow.CTAFlow.models.intraday_momentum import IntradayMomentumLight\nfrom CTAFlow.CTAFlow.models.base_models import CTALight, CTAXGBoost, CTARForest\nfrom CTAFlow.CTAFlow.config import INTRADAY_DATA_PATH\n\n# Set plotting style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(f\"✓ Imports successful\")\nprint(f\"✓ Data path: {INTRADAY_DATA_PATH}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_opening_returns(\n    intraday_df: pd.DataFrame,\n    session_open: time = time(8, 30),\n    opening_window: timedelta = timedelta(minutes=60),\n    price_col: str = \"Close\",\n) -> pd.Series:\n    \"\"\"\n    DEPRECATED: Use model.target_data instead.\n    \n    This function is kept for reference only. The IntradayMomentumLight class\n    pre-calculates target_data during initialization with proper lagging to\n    avoid lookahead bias. Always use model.target_data for consistency.\n    \"\"\"\n    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n        intraday_df.index = pd.to_datetime(intraday_df.index)\n    \n    work_df = pd.DataFrame({'price': intraday_df[price_col]})\n    work_df['date'] = work_df.index.normalize()\n    \n    session_open_offset = pd.Timedelta(hours=session_open.hour, minutes=session_open.minute)\n    work_df['session_start'] = work_df['date'] + session_open_offset\n    work_df['session_end'] = work_df['session_start'] + opening_window\n    \n    opening_mask = work_df.index >= work_df['session_start']\n    opening_data = work_df[opening_mask].groupby('date')['price'].first()\n    \n    closing_mask = (work_df.index >= work_df['session_start']) & (work_df.index < work_df['session_end'])\n    closing_data = work_df[closing_mask].groupby('date')['price'].last()\n    \n    opening_returns = np.log(closing_data / opening_data)\n    return opening_returns\n\n\ndef prepare_daily_data(intraday_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Create daily OHLC data from intraday bars.\"\"\"\n    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n        intraday_df.index = pd.to_datetime(intraday_df.index)\n    \n    daily = intraday_df.resample('1D').agg({\n        'Open': 'first',\n        'High': 'max',\n        'Low': 'min',\n        'Close': 'last',\n        'Volume': 'sum'\n    }).dropna()\n    \n    return daily\n\nprint(\"✓ Helper functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ticker = \"PL\"  # ticker for file lookup\n",
    "from CTAFlow.CTAFlow.data import read_exported_df\n",
    "from pathlib import Path\n",
    "\n",
    "# Load intraday data from CSV\n",
    "csv_path = Path('/content', 'drive', 'MyDrive', 'intraday', 'CSV') / f\"{ticker}_5min.csv\"\n",
    "print(f\"Loading {ticker} from {csv_path}\")\n",
    "\n",
    "intraday_data = read_exported_df(csv_path)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(intraday_data):,} bars\")\n",
    "print(f\"✓ Date range: {intraday_data.index[0].date()} to {intraday_data.index[-1].date()}\")\n",
    "print(f\"\\nData preview:\")\n",
    "intraday_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Initialize Model and Extract Target Data\n\n**Important**: We use the model's pre-calculated `target_data` attribute instead of manually calculating target returns. This ensures:\n- Consistency with the feature engineering pipeline\n- Proper handling of lookahead bias\n- Same target calculation used throughout the class"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize a base model to get target_data\n# This creates the target returns with proper lagging to avoid lookahead bias\nbase_model = IntradayMomentumLight(\n    intraday_data=intraday_data,\n    session_open=time(8, 30),\n    session_end=time(15, 0),\n    closing_length=timedelta(minutes=60),\n    tz=\"America/Chicago\",\n    base_model=CTALight,\n    task='regression'\n)\n\n# Use the pre-calculated target_data from the model\n# This is calculated during __init__ with proper date alignment\ntarget_returns = base_model.target_data\n\n# Prepare daily data for feature engineering\ndaily_df = prepare_daily_data(intraday_data)\n\nprint(f\"✓ Daily data: {len(daily_df)} days\")\nprint(f\"✓ Target returns: {len(target_returns)} days\")\nprint(f\"\\nTarget Statistics:\")\nprint(f\"  Mean: {target_returns.mean():.6f}\")\nprint(f\"  Std:  {target_returns.std():.6f}\")\nprint(f\"  Min:  {target_returns.min():.6f}\")\nprint(f\"  Max:  {target_returns.max():.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(model, daily_df, intraday_data):\n",
    "    \"\"\"Build comprehensive feature set for the model.\"\"\"\n",
    "    model.training_data = pd.DataFrame(index=daily_df.index)\n",
    "    \n",
    "    # Daily momentum features (lagged)\n",
    "    momentum_feats = model.add_daily_momentum_features(\n",
    "        daily_df,\n",
    "        lookbacks=(1, 5, 10, 20)\n",
    "    )\n",
    "    \n",
    "    # HAR volatility features\n",
    "    har_feats = model.har_volatility_features(\n",
    "        intraday_df=intraday_data,\n",
    "        horizons=(1, 5, 22)\n",
    "    )\n",
    "    \n",
    "    # Opening range volatility\n",
    "    opening_vol = model.opening_range_volatility(\n",
    "        intraday_df=intraday_data,\n",
    "        period_length=timedelta(minutes=60)\n",
    "    )\n",
    "    \n",
    "    # Previous high/low features\n",
    "    prev_hl_feats = model.prev_hl(horizon=5, add_as_feature=False, normalize=True)\n",
    "    prev_hl_df = pd.DataFrame({\n",
    "        '5_high': prev_hl_feats[0],\n",
    "        '5_low': prev_hl_feats[1]\n",
    "    })\n",
    "    \n",
    "    # Combine all features\n",
    "    model.training_data = pd.concat(\n",
    "        [momentum_feats, har_feats, opening_vol, prev_hl_df], \n",
    "        axis=1\n",
    "    ).dropna()\n",
    "    \n",
    "    return model.training_data\n",
    "\n",
    "print(\"✓ Feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Regression Models\n",
    "\n",
    "Predict continuous opening period returns using different model configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Baseline LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: BASELINE LIGHTGBM REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with default CTALight (regression)\n",
    "model_reg1 = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTALight,  # Default: task='regression'\n",
    "    task='regression'\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_reg1 = build_features(model_reg1, daily_df, intraday_data)\n",
    "print(f\"\\nFeatures built: {X_reg1.shape}\")\n",
    "print(f\"Feature columns: {list(X_reg1.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features and target\n",
    "common_idx = X_reg1.index.intersection(target_returns.index)\n",
    "X = X_reg1.loc[common_idx]\n",
    "y = target_returns.loc[common_idx]\n",
    "\n",
    "# Train/test split (80/20 temporal)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# Validation set for early stopping\n",
    "val_size = int(len(X_train) * 0.2)\n",
    "X_val = X_train.iloc[-val_size:]\n",
    "y_val = y_train.iloc[-val_size:]\n",
    "X_train_fit = X_train.iloc[:-val_size]\n",
    "y_train_fit = y_train.iloc[:-val_size]\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train_fit)} samples\")\n",
    "print(f\"  Val:   {len(X_val)} samples\")\n",
    "print(f\"  Test:  {len(X_test)} samples\")\n",
    "\n",
    "# Train model\n",
    "print(f\"\\nTraining baseline regressor...\")\n",
    "model_reg1.fit(\n",
    "    X_train_fit, y_train_fit,\n",
    "    eval_set=(X_val, y_val),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "metrics_reg1 = model_reg1.evaluate(X_test, y_test)\n",
    "print(f\"\\nBaseline Regression Metrics:\")\n",
    "print(f\"  R²:   {metrics_reg1['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_reg1['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_reg1['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_reg1['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Tuned LightGBM Regressor (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: TUNED LIGHTGBM REGRESSOR (GRID SEARCH)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_reg2 = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    tz=\"America/Chicago\",\n",
    "    task='regression'\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_reg2 = build_features(model_reg2, daily_df, intraday_data)\n",
    "common_idx2 = X_reg2.index.intersection(target_returns.index)\n",
    "X2 = X_reg2.loc[common_idx2]\n",
    "y2 = target_returns.loc[common_idx2]\n",
    "\n",
    "# Same split\n",
    "split_idx2 = int(len(X2) * 0.8)\n",
    "X_train2, X_test2 = X2.iloc[:split_idx2], X2.iloc[split_idx2:]\n",
    "y_train2, y_test2 = y2.iloc[:split_idx2], y2.iloc[split_idx2:]\n",
    "val_size2 = int(len(X_train2) * 0.2)\n",
    "X_val2 = X_train2.iloc[-val_size2:]\n",
    "y_val2 = y_train2.iloc[-val_size2:]\n",
    "X_train_fit2 = X_train2.iloc[:-val_size2]\n",
    "y_train_fit2 = y_train2.iloc[:-val_size2]\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'learning_rate': [0.03, 0.07],\n",
    "    'feature_fraction': [0.7, 0.9]\n",
    "}\n",
    "\n",
    "print(f\"\\nRunning grid search with {np.prod([len(v) for v in param_grid.values()])} combinations...\")\n",
    "\n",
    "grid_results = model_reg2.fit_with_grid_search(\n",
    "    X_train_fit2, y_train_fit2,\n",
    "    param_grid=param_grid,\n",
    "    eval_set=(X_val2, y_val2),\n",
    "    cv_folds=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_results['best_params']}\")\n",
    "print(f\"Best CV score: {grid_results['best_score']:.6f}\")\n",
    "\n",
    "# Evaluate\n",
    "metrics_reg2 = model_reg2.evaluate(X_test2, y_test2)\n",
    "print(f\"\\nTuned Regression Metrics:\")\n",
    "print(f\"  R²:   {metrics_reg2['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_reg2['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_reg2['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_reg2['directional_accuracy']:.2%}\")\n",
    "\n",
    "print(f\"\\nImprovement over baseline:\")\n",
    "print(f\"  ΔR²: {metrics_reg2['r2'] - metrics_reg1['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Model 3: XGBoost Regressor",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*70)\nprint(\"MODEL 3: XGBOOST REGRESSOR\")\nprint(\"=\"*70)\n\n# Initialize with XGBoost\nmodel_reg3 = IntradayMomentumLight(\n    intraday_data=intraday_data,\n    session_open=time(8, 30),\n    session_end=time(15, 0),\n    closing_length=timedelta(minutes=60),\n    tz=\"America/Chicago\",\n    base_model=CTAXGBoost,  # XGBoost model\n    task='regression'\n)\n\n# Build features\nX_reg3 = build_features(model_reg3, daily_df, intraday_data)\ncommon_idx3 = X_reg3.index.intersection(target_returns.index)\nX3 = X_reg3.loc[common_idx3]\ny3 = target_returns.loc[common_idx3]\n\n# Same split\nsplit_idx3 = int(len(X3) * 0.8)\nX_train3, X_test3 = X3.iloc[:split_idx3], X3.iloc[split_idx3:]\ny_train3, y_test3 = y3.iloc[:split_idx3], y3.iloc[split_idx3:]\nval_size3 = int(len(X_train3) * 0.2)\nX_val3 = X_train3.iloc[-val_size3:]\ny_val3 = y_train3.iloc[-val_size3:]\nX_train_fit3 = X_train3.iloc[:-val_size3]\ny_train_fit3 = y_train3.iloc[:-val_size3]\n\nprint(f\"Data split:\")\nprint(f\"  Train: {len(X_train_fit3)} samples\")\nprint(f\"  Val:   {len(X_val3)} samples\")\nprint(f\"  Test:  {len(X_test3)} samples\")\n\n# Train XGBoost model\nprint(f\"\\nTraining XGBoost regressor...\")\nmodel_reg3.fit(\n    X_train_fit3, y_train_fit3,\n    eval_set=(X_val3, y_val3),\n    early_stopping_rounds=50,\n    num_boost_round=1000\n)\n\n# Evaluate\nmetrics_reg3 = model_reg3.evaluate(X_test3, y_test3)\nprint(f\"\\nXGBoost Regression Metrics:\")\nprint(f\"  R²:   {metrics_reg3['r2']:.4f}\")\nprint(f\"  RMSE: {metrics_reg3['rmse']:.6f}\")\nprint(f\"  MAE:  {metrics_reg3['mae']:.6f}\")\nprint(f\"  Dir Acc: {metrics_reg3['directional_accuracy']:.2%}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Model 4: Random Forest Regressor",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*70)\nprint(\"MODEL 4: RANDOM FOREST REGRESSOR\")\nprint(\"=\"*70)\n\n# Initialize with Random Forest\nmodel_reg4 = IntradayMomentumLight(\n    intraday_data=intraday_data,\n    session_open=time(8, 30),\n    session_end=time(15, 0),\n    closing_length=timedelta(minutes=60),\n    tz=\"America/Chicago\",\n    base_model=CTARForest,  # Random Forest model\n    task='regression'\n)\n\n# Build features\nX_reg4 = build_features(model_reg4, daily_df, intraday_data)\ncommon_idx4 = X_reg4.index.intersection(target_returns.index)\nX4 = X_reg4.loc[common_idx4]\ny4 = target_returns.loc[common_idx4]\n\n# Same split\nsplit_idx4 = int(len(X4) * 0.8)\nX_train4, X_test4 = X4.iloc[:split_idx4], X4.iloc[split_idx4:]\ny_train4, y_test4 = y4.iloc[:split_idx4], y4.iloc[split_idx4:]\n\nprint(f\"Data split:\")\nprint(f\"  Train: {len(X_train4)} samples\")\nprint(f\"  Test:  {len(X_test4)} samples\")\n\n# Train Random Forest model (no early stopping for RF)\nprint(f\"\\nTraining Random Forest regressor...\")\nmodel_reg4.fit(X_train4, y_train4)\n\n# Evaluate\nmetrics_reg4 = model_reg4.evaluate(X_test4, y_test4)\nprint(f\"\\nRandom Forest Regression Metrics:\")\nprint(f\"  R²:   {metrics_reg4['r2']:.4f}\")\nprint(f\"  RMSE: {metrics_reg4['rmse']:.6f}\")\nprint(f\"  MAE:  {metrics_reg4['mae']:.6f}\")\nprint(f\"  Dir Acc: {metrics_reg4['directional_accuracy']:.2%}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate predictions from models\ny_pred_reg1 = model_reg1.predict(X_test)\ny_pred_reg2 = model_reg2.predict(X_test2)\ny_pred_reg3 = model_reg3.predict(X_test3)\ny_pred_reg4 = model_reg4.predict(X_test4)\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Baseline scatter\naxes[0, 0].scatter(y_test, y_pred_reg1, alpha=0.6, s=30, label='Predictions', edgecolors='black', linewidth=0.5)\n# Use data range for perfect line instead of min/max which can be outliers\nq_low, q_high = y_test.quantile([0.05, 0.95])\naxes[0, 0].plot([q_low, q_high], [q_low, q_high], 'r--', linewidth=2, alpha=0.7, label='Perfect')\naxes[0, 0].set_xlabel('Actual Returns', fontsize=11)\naxes[0, 0].set_ylabel('Predicted Returns', fontsize=11)\naxes[0, 0].set_title(f'Model 1: LightGBM Baseline (R²={metrics_reg1[\"r2\"]:.4f})', fontsize=12, fontweight='bold')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Tuned scatter\naxes[0, 1].scatter(y_test2, y_pred_reg2, alpha=0.6, s=30, color='green', label='Predictions', edgecolors='black', linewidth=0.5)\nq_low2, q_high2 = y_test2.quantile([0.05, 0.95])\naxes[0, 1].plot([q_low2, q_high2], [q_low2, q_high2], 'r--', linewidth=2, alpha=0.7, label='Perfect')\naxes[0, 1].set_xlabel('Actual Returns', fontsize=11)\naxes[0, 1].set_ylabel('Predicted Returns', fontsize=11)\naxes[0, 1].set_title(f'Model 2: LightGBM Tuned (R²={metrics_reg2[\"r2\"]:.4f})', fontsize=12, fontweight='bold')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Model comparison bar chart\nmodel_names = ['LightGBM\\nBaseline', 'LightGBM\\nTuned', 'XGBoost', 'Random\\nForest']\nr2_scores = [metrics_reg1['r2'], metrics_reg2['r2'], metrics_reg3['r2'], metrics_reg4['r2']]\ncolors = ['steelblue', 'green', 'orange', 'purple']\nbars = axes[1, 0].bar(model_names, r2_scores, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\naxes[1, 0].set_ylabel('R² Score', fontsize=11)\naxes[1, 0].set_title('Model Performance Comparison (R²)', fontsize=12, fontweight='bold')\naxes[1, 0].grid(True, alpha=0.3, axis='y')\naxes[1, 0].set_ylim([min(r2_scores) - 0.05, max(r2_scores) + 0.05])\n# Add value labels on bars\nfor bar, score in zip(bars, r2_scores):\n    height = bar.get_height()\n    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n                    f'{score:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\n# Feature importance (tuned model)\ntop_features = model_reg2.model.get_feature_importance(importance_type='gain', top_n=10)\nfeatures = list(top_features.keys())\nimportances = list(top_features.values())\n# Sort by importance\nsorted_idx = sorted(range(len(importances)), key=lambda k: importances[k])\nfeatures_sorted = [features[i] for i in sorted_idx]\nimportances_sorted = [importances[i] for i in sorted_idx]\naxes[1, 1].barh(features_sorted, importances_sorted, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.8)\naxes[1, 1].set_xlabel('Importance (Gain)', fontsize=11)\naxes[1, 1].set_title('Top 10 Features - LightGBM Tuned Model', fontsize=12, fontweight='bold')\naxes[1, 1].grid(True, alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Classification Models\n",
    "\n",
    "Predict opening period direction (binary) or regime (multiclass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Binary Classifier (Up/Down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 3: BINARY CLASSIFIER (UP/DOWN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with binary classification task\n",
    "model_clf_binary = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTALight,\n",
    "    task='binary_classification'  # Binary classification\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_clf_bin = build_features(model_clf_binary, daily_df, intraday_data)\n",
    "\n",
    "# Create binary target (0=down, 1=up)\n",
    "y_clf_binary = model_clf_binary.create_clf_target(\n",
    "    n_classes=2,\n",
    "    add_as_feature=False\n",
    ")\n",
    "\n",
    "print(f\"\\nBinary target distribution:\")\n",
    "print(y_clf_binary.value_counts(normalize=True))\n",
    "print(f\"\\nFeatures: {X_clf_bin.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align and split\ncommon_idx_bin = X_clf_bin.index.intersection(y_clf_binary.index)\nX_bin = X_clf_bin.loc[common_idx_bin]\ny_bin = y_clf_binary.loc[common_idx_bin]\n\nsplit_idx_bin = int(len(X_bin) * 0.8)\nX_train_bin, X_test_bin = X_bin.iloc[:split_idx_bin], X_bin.iloc[split_idx_bin:]\ny_train_bin, y_test_bin = y_bin.iloc[:split_idx_bin], y_bin.iloc[split_idx_bin:]\n\nval_size_bin = int(len(X_train_bin) * 0.2)\nX_val_bin = X_train_bin.iloc[-val_size_bin:]\ny_val_bin = y_train_bin.iloc[-val_size_bin:]\nX_train_fit_bin = X_train_bin.iloc[:-val_size_bin]\ny_train_fit_bin = y_train_bin.iloc[:-val_size_bin]\n\nprint(f\"Data split:\")\nprint(f\"  Train: {len(X_train_fit_bin)} samples\")\nprint(f\"  Val:   {len(X_val_bin)} samples\")\nprint(f\"  Test:  {len(X_test_bin)} samples\")\n\n# Train binary classifier\nprint(f\"\\nTraining binary classifier...\")\nmodel_clf_binary.fit(\n    X_train_fit_bin, y_train_fit_bin,\n    eval_set=(X_val_bin, y_val_bin),\n    early_stopping_rounds=50,\n    num_boost_round=1000\n)\n\n# Predict and convert probabilities to class labels\n# LightGBM binary classification returns probabilities for class 1\ny_pred_proba_bin = model_clf_binary.predict(X_test_bin)\ny_pred_bin = (y_pred_proba_bin > 0.5).astype(int)  # Convert to class labels\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint(f\"\\nBinary Classification Metrics:\")\nprint(f\"  Accuracy:  {accuracy_score(y_test_bin, y_pred_bin):.4f}\")\nprint(f\"  Precision: {precision_score(y_test_bin, y_pred_bin):.4f}\")\nprint(f\"  Recall:    {recall_score(y_test_bin, y_pred_bin):.4f}\")\nprint(f\"  F1 Score:  {f1_score(y_test_bin, y_pred_bin):.4f}\")\n\nprint(f\"\\nClassification Report:\")\nprint(classification_report(y_test_bin, y_pred_bin, target_names=['Down', 'Up']))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_bin = confusion_matrix(y_test_bin, y_pred_bin)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Binary Classification Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Multiclass Classifier (Down/Neutral/Up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 4: MULTICLASS CLASSIFIER (DOWN/NEUTRAL/UP)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with multiclass task\n",
    "model_clf_multi = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTALight,\n",
    "    task='multiclass',  # Multiclass classification\n",
    "    num_class=3\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_clf_multi = build_features(model_clf_multi, daily_df, intraday_data)\n",
    "\n",
    "# Create multiclass target with thresholds (0=down, 1=neutral, 2=up)\n",
    "# Use 25th and 75th percentiles as thresholds\n",
    "lower_threshold = target_returns.quantile(0.25)\n",
    "upper_threshold = target_returns.quantile(0.75)\n",
    "\n",
    "y_clf_multi = model_clf_multi.create_clf_target(\n",
    "    n_classes=3,\n",
    "    lower_bound=lower_threshold,\n",
    "    upper_bound=upper_threshold,\n",
    "    add_as_feature=False\n",
    ")\n",
    "\n",
    "print(f\"\\nThresholds:\")\n",
    "print(f\"  Lower (25th %ile): {lower_threshold:.6f}\")\n",
    "print(f\"  Upper (75th %ile): {upper_threshold:.6f}\")\n",
    "\n",
    "print(f\"\\nMulticlass target distribution:\")\n",
    "print(y_clf_multi.value_counts(normalize=True).sort_index())\n",
    "print(f\"\\nFeatures: {X_clf_multi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Align and split\ncommon_idx_multi = X_clf_multi.index.intersection(y_clf_multi.index)\nX_multi = X_clf_multi.loc[common_idx_multi]\ny_multi = y_clf_multi.loc[common_idx_multi]\n\nsplit_idx_multi = int(len(X_multi) * 0.8)\nX_train_multi, X_test_multi = X_multi.iloc[:split_idx_multi], X_multi.iloc[split_idx_multi:]\ny_train_multi, y_test_multi = y_multi.iloc[:split_idx_multi], y_multi.iloc[split_idx_multi:]\n\nval_size_multi = int(len(X_train_multi) * 0.2)\nX_val_multi = X_train_multi.iloc[-val_size_multi:]\ny_val_multi = y_train_multi.iloc[-val_size_multi:]\nX_train_fit_multi = X_train_multi.iloc[:-val_size_multi]\ny_train_fit_multi = y_train_multi.iloc[:-val_size_multi]\n\nprint(f\"Data split:\")\nprint(f\"  Train: {len(X_train_fit_multi)} samples\")\nprint(f\"  Val:   {len(X_val_multi)} samples\")\nprint(f\"  Test:  {len(X_test_multi)} samples\")\n\n# Train multiclass classifier\nprint(f\"\\nTraining multiclass classifier...\")\nmodel_clf_multi.fit(\n    X_train_fit_multi, y_train_fit_multi,\n    eval_set=(X_val_multi, y_val_multi),\n    early_stopping_rounds=50,\n    num_boost_round=1000\n)\n\n# Predict and convert probabilities to class labels\n# LightGBM multiclass returns probabilities for each class\ny_pred_proba_multi = model_clf_multi.predict(X_test_multi)\n# For multiclass, predict returns (n_samples, n_classes) probabilities\n# Use argmax to get the class with highest probability\nif y_pred_proba_multi.ndim > 1:\n    y_pred_multi = np.argmax(y_pred_proba_multi, axis=1)\nelse:\n    # If it returns 1D, it's already class labels\n    y_pred_multi = y_pred_proba_multi.astype(int)\n\nprint(f\"\\nMulticlass Classification Metrics:\")\nprint(f\"  Accuracy: {accuracy_score(y_test_multi, y_pred_multi):.4f}\")\nprint(f\"  Macro F1: {f1_score(y_test_multi, y_pred_multi, average='macro'):.4f}\")\n\nprint(f\"\\nClassification Report:\")\nprint(classification_report(y_test_multi, y_pred_multi, \n                          target_names=['Down', 'Neutral', 'Up']))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_multi = confusion_matrix(y_test_multi, y_pred_multi)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Down', 'Neutral', 'Up'],\n",
    "            yticklabels=['Down', 'Neutral', 'Up'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Multiclass Classification Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Binary classifier features\ntop_bin = model_clf_binary.model.get_feature_importance(importance_type='gain', top_n=10)\nfeatures_bin = list(top_bin.keys())\nimportances_bin = list(top_bin.values())\n# Sort by importance\nsorted_idx_bin = sorted(range(len(importances_bin)), key=lambda k: importances_bin[k])\nfeatures_bin_sorted = [features_bin[i] for i in sorted_idx_bin]\nimportances_bin_sorted = [importances_bin[i] for i in sorted_idx_bin]\naxes[0].barh(features_bin_sorted, importances_bin_sorted, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.8)\naxes[0].set_xlabel('Importance (Gain)', fontsize=11)\naxes[0].set_title('Top 10 Features - Binary Classifier', fontsize=12, fontweight='bold')\naxes[0].grid(True, alpha=0.3, axis='x')\n\n# Multiclass classifier features\ntop_multi = model_clf_multi.model.get_feature_importance(importance_type='gain', top_n=10)\nfeatures_multi = list(top_multi.keys())\nimportances_multi = list(top_multi.values())\n# Sort by importance\nsorted_idx_multi = sorted(range(len(importances_multi)), key=lambda k: importances_multi[k])\nfeatures_multi_sorted = [features_multi[i] for i in sorted_idx_multi]\nimportances_multi_sorted = [importances_multi[i] for i in sorted_idx_multi]\naxes[1].barh(features_multi_sorted, importances_multi_sorted, color='green', alpha=0.7, edgecolor='black', linewidth=0.8)\naxes[1].set_xlabel('Importance (Gain)', fontsize=11)\naxes[1].set_title('Top 10 Features - Multiclass Classifier', fontsize=12, fontweight='bold')\naxes[1].grid(True, alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Summary: Model Comparison\n\nComparison of all models across regression and classification tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"MODEL COMPARISON SUMMARY\")\nprint(\"=\"*70)\n\nprint(\"\\nREGRESSION MODELS:\")\nprint(\"-\" * 70)\nprint(f\"Model 1 (LightGBM Baseline): R² = {metrics_reg1['r2']:.4f}, RMSE = {metrics_reg1['rmse']:.6f}\")\nprint(f\"Model 2 (LightGBM Tuned):    R² = {metrics_reg2['r2']:.4f}, RMSE = {metrics_reg2['rmse']:.6f}\")\nprint(f\"Model 3 (XGBoost):           R² = {metrics_reg3['r2']:.4f}, RMSE = {metrics_reg3['rmse']:.6f}\")\nprint(f\"Model 4 (Random Forest):     R² = {metrics_reg4['r2']:.4f}, RMSE = {metrics_reg4['rmse']:.6f}\")\n\nprint(\"\\nCLASSIFICATION MODELS:\")\nprint(\"-\" * 70)\nprint(f\"Model 5 (Binary):            Accuracy = {accuracy_score(y_test_bin, y_pred_bin):.4f}, F1 = {f1_score(y_test_bin, y_pred_bin):.4f}\")\nprint(f\"Model 6 (Multiclass):        Accuracy = {accuracy_score(y_test_multi, y_pred_multi):.4f}, F1 = {f1_score(y_test_multi, y_pred_multi, average='macro'):.4f}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"KEY FINDINGS:\")\nprint(\"=\"*70)\nprint(\"✓ Target data uses model.target_data to ensure consistency and avoid lookahead bias\")\nprint(\"✓ IntradayMomentumLight supports multiple base models (LightGBM, XGBoost, RandomForest)\")\nprint(\"✓ Feature engineering is model-agnostic (same features for all models)\")\nprint(\"✓ Grid search can improve LightGBM regression performance\")\nprint(\"✓ Different models show varying prediction accuracy - compare R² and RMSE\")\nprint(\"✓ Binary and multiclass classification achieve reasonable directional accuracy\")\nprint(\"✓ All models properly handle temporal splits to avoid lookahead bias\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
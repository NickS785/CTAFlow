{
 "cells": [
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHuUbbC5bAkW",
    "outputId": "993237c5-3ff7-4d60-b446-5dd62a648902"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'CTAFlow'...\n",
      "remote: Enumerating objects: 2983, done.\u001b[K\n",
      "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
      "remote: Compressing objects: 100% (185/185), done.\u001b[K\n",
      "remote: Total 2983 (delta 163), reused 149 (delta 104), pack-reused 2694 (from 2)\u001b[K\n",
      "Receiving objects: 100% (2983/2983), 17.76 MiB | 6.51 MiB/s, done.\n",
      "Resolving deltas: 100% (2105/2105), done.\n",
      "Obtaining file:///content/CTAFlow\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (1.6.1)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (4.6.0)\n",
      "Requirement already satisfied: xgboost>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (3.10.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (0.13.2)\n",
      "Requirement already satisfied: tables>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (3.10.2)\n",
      "Requirement already satisfied: toml>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (0.10.2)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.12/dist-packages (from CTAFlow==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm>=3.0.0->CTAFlow==1.0.0) (1.16.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->CTAFlow==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->CTAFlow==1.0.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->CTAFlow==1.0.0) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->CTAFlow==1.0.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->CTAFlow==1.0.0) (3.6.0)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.12/dist-packages (from tables>=3.6.0->CTAFlow==1.0.0) (2.14.1)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from tables>=3.6.0->CTAFlow==1.0.0) (9.0.0)\n",
      "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from tables>=3.6.0->CTAFlow==1.0.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from tables>=3.6.0->CTAFlow==1.0.0) (4.15.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost>=1.5.0->CTAFlow==1.0.0) (2.28.9)\n",
      "Requirement already satisfied: ndindex in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (1.10.1)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (1.1.2)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (4.5.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->CTAFlow==1.0.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->blosc2>=2.3.0->tables>=3.6.0->CTAFlow==1.0.0) (2025.11.12)\n",
      "Building wheels for collected packages: CTAFlow\n",
      "  Building editable for CTAFlow (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for CTAFlow: filename=ctaflow-1.0.0-0.editable-py3-none-any.whl size=7150 sha256=e8bb432f9c7ae505a636e679d15575da912146ad85e6d5f4177dcf23b54eb0a9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wb6b1a9r/wheels/88/a3/d1/a7ec03ac18ed6e567435cf8ef4bb473f62e14fd8ef8f1c5ba1\n",
      "Successfully built CTAFlow\n",
      "Installing collected packages: CTAFlow\n",
      "Successfully installed CTAFlow-1.0.0\n",
      "Cloning into 'SierraPy'...\n",
      "remote: Enumerating objects: 195, done.\u001b[K\n",
      "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
      "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
      "Receiving objects: 100% (195/195), 95.85 KiB | 1.96 MiB/s, done.\n",
      "remote: Total 195 (delta 93), reused 42 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Resolving deltas: 100% (93/93), done.\n",
      "Obtaining file:///content/SierraPy\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from sierrapy==0.1.0) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from sierrapy==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->sierrapy==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->sierrapy==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->sierrapy==0.1.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->sierrapy==0.1.0) (1.17.0)\n",
      "Building wheels for collected packages: sierrapy\n",
      "  Building editable for sierrapy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sierrapy: filename=sierrapy-0.1.0-0.editable-py3-none-any.whl size=7295 sha256=bb2ee74b9559ea1cbf31dc0c3b459d526df50d532d18793ead85935c5c905b89\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zroez3g3/wheels/cf/0f/27/f522b0cfd6b4a98ce4ce3ed59d8c9af770c72da267768b933e\n",
      "Successfully built sierrapy\n",
      "Installing collected packages: sierrapy\n",
      "Successfully installed sierrapy-0.1.0\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "\n",
    "# @title\n",
    "!git clone https://github.com/NickS785/CTAFlow -b v2\n",
    "\n",
    "!pip install -e CTAFlow\n",
    "!git clone https://github.com/NickS785/SierraPy\n",
    "!pip install -e SierraPy\n"
   ]
  },
  {
   "metadata": {
    "id": "cpZvUmS2bAkZ"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"//content/SierraPy\")\n",
    "sys.path.insert(1, \"//content/CTAFlow/CTAFlow\")\n",
    "from SierraPy import sierrapy"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3uNYJ6SbAkb",
    "outputId": "75d8395e-8bd3-4b40-9a1c-e9137ef50c7c"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebIVIv39bAkd"
   },
   "source": [
    "# Opening Returns Prediction with IntradayMomentum",
    "",
    "This notebook demonstrates:",
    "1. **Regression Models** - LightGBM (baseline & tuned), XGBoost, Random Forest",
    "2. **Classification Models** - Binary and multiclass LightGBM classifiers",
    "3. **Model Comparison** - Compare performance across different algorithms",
    "",
    "**Features Used:**",
    "- Short-term daily momentum (1d, 5d, 10d, 20d) - properly lagged",
    "- HAR-style realized volatility (1d, 5d, 22d)",
    "- Opening range volatility (first 60 minutes)",
    "- Previous high/low features",
    "",
    "**Target**: Returns during the opening period (first 60 minutes of session)",
    "**Important**: Uses `model.target_data` to ensure consistency and avoid lookahead bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjCKLD8ubAkg"
   },
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R34eDgrJbAkh",
    "outputId": "7d0d1f19-9565-4ce3-872c-4d2cffd83048"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/SierraPy\n",
      "Warning: Some CTAFlow components could not be imported: No module named 'CTAFlow.forecaster'\n",
      "Please ensure all dependencies are installed: pip install -r requirements.txt\n",
      "Warning: Some CTAFlow components could not be imported: No module named 'CTAFlow.CTAFlow.forecaster'\n",
      "Please ensure all dependencies are installed: pip install -r requirements.txt\n",
      "✓ Imports successful\n",
      "✓ Data path: F:\\Data\\intraday\n",
      "✓ Imports successful\n",
      "✓ Data path: F:\\Data\\intraday\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import time, timedelta\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Add parent directories to path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "%cd SierraPy\n",
    "from CTAFlow.CTAFlow.models.intraday_momentum import IntradayMomentum\n",
    "from CTAFlow.CTAFlow.models.base_models import CTALight\n",
    "from CTAFlow.CTAFlow.config import INTRADAY_DATA_PATH\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"✓ Imports successful\")\n",
    "print(f\"✓ Data path: {INTRADAY_DATA_PATH}\")\n",
    "\n",
    "print(f\"✓ Imports successful\")\n",
    "print(f\"✓ Data path: {INTRADAY_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRViQUgYbAkm"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byyBvEwEbAko",
    "outputId": "f335dddd-0595-43a7-d055-1bbb447e8dc3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_opening_returns(\n",
    "    intraday_df: pd.DataFrame,\n",
    "    session_open: time = time(8, 30),\n",
    "    opening_window: timedelta = timedelta(minutes=60),\n",
    "    price_col: str = \"Close\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    DEPRECATED: Use model.target_data instead.\n",
    "\n",
    "    This function is kept for reference only. The IntradayMomentum class\n",
    "    pre-calculates target_data during initialization with proper lagging to\n",
    "    avoid lookahead bias. Always use model.target_data for consistency.\n",
    "    \"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "\n",
    "    work_df = pd.DataFrame({'price': intraday_df[price_col]})\n",
    "    work_df['date'] = work_df.index.normalize()\n",
    "\n",
    "    session_open_offset = pd.Timedelta(hours=session_open.hour, minutes=session_open.minute)\n",
    "    work_df['session_start'] = work_df['date'] + session_open_offset\n",
    "    work_df['session_end'] = work_df['session_start'] + opening_window\n",
    "\n",
    "    opening_mask = work_df.index >= work_df['session_start']\n",
    "    opening_data = work_df[opening_mask].groupby('date')['price'].first()\n",
    "\n",
    "    closing_mask = (work_df.index >= work_df['session_start']) & (work_df.index < work_df['session_end'])\n",
    "    closing_data = work_df[closing_mask].groupby('date')['price'].last()\n",
    "\n",
    "    opening_returns = np.log(closing_data / opening_data)\n",
    "    return opening_returns\n",
    "\n",
    "\n",
    "def prepare_daily_data(intraday_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create daily OHLC data from intraday bars.\"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "\n",
    "    daily = intraday_df.resample('1D').agg({\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    }).dropna()\n",
    "\n",
    "    return daily\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJGPef40bAkp"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "metadata": {
    "id": "lrd6qhXlbAkq"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ticker = \"RB\"  # ticker for file lookup\n\nsupplementary_tickers = {\"PL\": [\"PA\", \"GC\"],\n                         \"RB\": [\"HO\", \"CL\"],\n                         \"CS\": [\"RB\", \"CL\", \"HO\"]}\nfrom CTAFlow.CTAFlow.data import read_exported_df, read_synthetic_csv\nfrom pathlib import Path\n\n# Load intraday data from CSV\npath = Path('/content', 'drive', 'MyDrive', 'intraday', 'CSV')\ncsv_path = path / f\"{ticker}_5min.csv\"\n\nsupplementary = {p:read_exported_df(path / f\"{p}_5min.csv\") for p in supplementary_tickers[ticker]}\nprint(f\"Loading {ticker} from {csv_path}\")\n\nintraday_data = read_exported_df(csv_path)\n\nprint(f\"\\n✓ Loaded {len(intraday_data):,} bars\")\nprint(f\"✓ Date range: {intraday_data.index[0].date()} to {intraday_data.index[-1].date()}\")\nprint(f\"\\nData preview:\")\nintraday_data.head()"
  },
  {
   "cell_type": "markdown",
   "source": "## Session Configuration\n\n**Centralized session parameters** - Change these values once to affect all models in the notebook",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SESSION CONFIGURATION - Change these values to affect all models\n# =============================================================================\nfrom datetime import time, timedelta\n\n# Session timing parameters\nSESSION_START = time(hour=2, minute=30)\nSESSION_END = time(hour=11, minute=30)\nCLOSING_LENGTH = timedelta(minutes=90)\nTIMEZONE = \"America/Chicago\"\nSESSION_TARGET = \"close\"  # or \"open\"\n\n# Feature engineering time parameters\nKEY_RETURN_TIMES = [time(3, 30), time(9, 30)]\nOPENING_VOL_PERIOD = timedelta(minutes=60)\nTARGET_PERIOD = timedelta(minutes=480)\n\n# Model configuration\nUSE_GPU = True\n\nprint(\"=\"*70)\nprint(\"SESSION CONFIGURATION\")\nprint(\"=\"*70)\nprint(f\"Session: {SESSION_START} to {SESSION_END}\")\nprint(f\"Closing period length: {CLOSING_LENGTH}\")\nprint(f\"Target period length: {TARGET_PERIOD}\")\nprint(f\"Opening volume period: {OPENING_VOL_PERIOD}\")\nprint(f\"Key return times: {KEY_RETURN_TIMES}\")\nprint(f\"Timezone: {TIMEZONE}\")\nprint(f\"GPU enabled: {USE_GPU}\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycyuMYHRbAkq"
   },
   "source": [
    "## Initialize Model and Extract Target Data\n",
    "\n",
    "**Important**: We use the model's pre-calculated `target_data` attribute instead of manually calculating target returns. This ensures:\n",
    "- Consistency with the feature engineering pipeline\n",
    "- Proper handling of lookahead bias\n",
    "- Same target calculation used throughout the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgbXuAC0bAkr"
   },
   "outputs": [],
   "source": [
    "# Initialize a base model to get target_data\n",
    "# This creates the target returns with proper lagging to avoid lookahead bias\n",
    "base_model = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    base_model=CTALight,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    use_gpu=USE_GPU\n",
    ")\n",
    "\n",
    "# Use the pre-calculated target_data from the model\n",
    "# This is calculated during __init__ with proper date alignment\n",
    "target_returns = base_model.target_data\n",
    "\n",
    "# Prepare daily data for feature engineering\n",
    "daily_df = prepare_daily_data(intraday_data)\n",
    "\n",
    "print(f\"✓ Daily data: {len(daily_df)} days\")\n",
    "print(f\"✓ Target returns: {len(target_returns)} days\")\n",
    "print(f\"\\nTarget Statistics:\")\n",
    "print(f\"  Mean: {target_returns.mean():.6f}\")\n",
    "print(f\"  Std:  {target_returns.std():.6f}\")\n",
    "print(f\"  Min:  {target_returns.min():.6f}\")\n",
    "print(f\"  Max:  {target_returns.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBJl5_W8bAkr"
   },
   "source": [
    "## Feature Engineering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEYxEyAfbAks"
   },
   "outputs": [],
   "source": "def build_features(model, daily_df, intraday_data, \n                   key_return_times=KEY_RETURN_TIMES,\n                   target_period=TARGET_PERIOD,\n                   opening_vol_period=OPENING_VOL_PERIOD):\n    \"\"\"Build comprehensive feature set for the model using centralized configuration.\"\"\"\n    model.training_data = pd.DataFrame(index=daily_df.index)\n\n    # Daily momentum features (lagged)\n    momentum_feats = model.add_daily_momentum_features(\n        daily_df,\n        lookbacks=(1, 10, 20)\n    )\n\n    # HAR volatility features\n    har_feats = model.har_volatility_features(\n        intraday_df=intraday_data,\n        horizons=(1, 5)\n    )\n\n    # Opening range volatility\n    opening_vol = model.opening_range_volatility(\n        intraday_df=intraday_data,\n        period_length=opening_vol_period,\n    )\n\n    # Target time returns - use the last key return time as session end start\n    session_end_start = key_return_times[-1]\n    \n    target_time = model.target_time_returns(\n        session_end_start, \n        period_length=target_period, \n        add_as_feature=True\n    )\n    \n    t2_time = model.target_time_returns(\n        key_return_times, \n        period_length=timedelta(minutes=60), \n        add_as_feature=True\n    )\n\n    # Target volumes\n    target_volume = model.target_time_volume(\n        session_end_start, \n        period_length=target_period, \n        add_as_feature=True\n    )\n    \n    opening_volume = model.target_time_volume(\n        key_return_times, \n        period_length=timedelta(minutes=60), \n        add_as_feature=True\n    )\n    \n    # Correlations\n    tickers = [*supplementary.keys()]\n    corrs = model.intraday_correlation(\n        tickers[-1], \n        target_time=session_end_start,  \n        n_bars=8, \n        add_as_feature=True\n    )\n\n    print(model.training_data.head())\n    return model.training_data\n\nprint(\"✓ Feature engineering function defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZkxQzLSbAks"
   },
   "source": [
    "# Part 1: Regression Models\n",
    "\n",
    "Predict continuous opening period returns using different model configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sPX26sQbAkt"
   },
   "source": [
    "## Model 1: Baseline LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfdI4jJHbAku"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: BASELINE LIGHTGBM REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with default CTALight (regression)\n",
    "model_reg1 = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    base_model=CTALight,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    use_gpu=USE_GPU\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_reg1 = build_features(model_reg1, daily_df, intraday_data)\n",
    "print(f\"\\nFeatures built: {X_reg1.shape}\")\n",
    "print(f\"Feature columns: {list(X_reg1.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-Au8OcSbAkv"
   },
   "outputs": [],
   "source": [
    "# Align features and target\n",
    "common_idx = X_reg1.index.intersection(target_returns.index)\n",
    "X = X_reg1.loc[common_idx]\n",
    "y = target_returns.loc[common_idx]\n",
    "\n",
    "# Train/test split (80/20 temporal)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# Validation set for early stopping\n",
    "val_size = int(len(X_train) * 0.2)\n",
    "X_val = X_train.iloc[-val_size:]\n",
    "y_val = y_train.iloc[-val_size:]\n",
    "X_train_fit = X_train.iloc[:-val_size]\n",
    "y_train_fit = y_train.iloc[:-val_size]\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train_fit)} samples\")\n",
    "print(f\"  Val:   {len(X_val)} samples\")\n",
    "print(f\"  Test:  {len(X_test)} samples\")\n",
    "\n",
    "# Train model\n",
    "print(f\"\\nTraining baseline regressor...\")\n",
    "model_reg1.fit(\n",
    "    X_train_fit, y_train_fit,\n",
    "    eval_set=(X_val, y_val),\n",
    "    early_stopping_rounds=100,\n",
    "    num_boost_round=500\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "metrics_reg1 = model_reg1.evaluate(X_test, y_test)\n",
    "print(f\"\\nBaseline Regression Metrics:\")\n",
    "print(f\"  R²:   {metrics_reg1['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_reg1['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_reg1['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_reg1['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1XqPWtybAkv"
   },
   "source": [
    "## Model 2: Tuned LightGBM Regressor (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO1VdGFmbAkw"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: TUNED LIGHTGBM REGRESSOR (GRID SEARCH)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_reg2 = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    base_model=CTALight,\n",
    "    use_gpu=USE_GPU\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_reg2 = build_features(model_reg2, daily_df, intraday_data)\n",
    "common_idx2 = X_reg2.index.intersection(target_returns.index)\n",
    "X2 = X_reg2.loc[common_idx2]\n",
    "y2 = target_returns.loc[common_idx2]\n",
    "\n",
    "# Same split\n",
    "split_idx2 = int(len(X2) * 0.8)\n",
    "X_train2, X_test2 = X2.iloc[:split_idx2], X2.iloc[split_idx2:]\n",
    "y_train2, y_test2 = y2.iloc[:split_idx2], y2.iloc[split_idx2:]\n",
    "val_size2 = int(len(X_train2) * 0.2)\n",
    "X_val2 = X_train2.iloc[-val_size2:]\n",
    "y_val2 = y_train2.iloc[-val_size2:]\n",
    "X_train_fit2 = X_train2.iloc[:-val_size2]\n",
    "y_train_fit2 = y_train2.iloc[:-val_size2]\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'learning_rate': [0.02, 0.07, 0.1],\n",
    "    'feature_fraction': [0.7, 0.9]\n",
    "}\n",
    "\n",
    "print(f\"\\nRunning grid search with {np.prod([len(v) for v in param_grid.values()])} combinations...\")\n",
    "\n",
    "grid_results = model_reg2.fit_with_grid_search(\n",
    "    X_train_fit2, y_train_fit2,\n",
    "    eval_set=(X_val2, y_val2),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Best parameters: {grid_results['best_params']}\")\n",
    "print(f\"Best mean CV score: {grid_results['best_mean_score']:.6f}\")\n",
    "print(f\"Best individual fold: {grid_results['best_fold_score']:.6f}\")\n",
    "print(f\"Worst individual fold: {grid_results['worst_fold_score']:.6f}\")\n",
    "print(f\"Std across folds: {grid_results['std_score']:.6f}\")\n",
    "\n",
    "# Evaluate\n",
    "metrics_reg2 = model_reg2.evaluate(X_test2, y_test2)\n",
    "print(f\"\\nTuned Regression Metrics:\")\n",
    "print(f\"  R²:   {metrics_reg2['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_reg2['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_reg2['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_reg2['directional_accuracy']:.2%}\")\n",
    "\n",
    "print(f\"\\nImprovement over baseline:\")\n",
    "print(f\"  ΔR²: {metrics_reg2['r2'] - metrics_reg1['r2']:.4f}\")"
   ],
   "metadata": {
    "id": "9vgxRXz0g1Sr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 3: XGBoost Regressor"
   ],
   "metadata": {
    "id": "1rmGVTO6bAkw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 3: XGBOOST REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "from CTAFlow.CTAFlow.models.base_models import CTAXGBoost, CTARForest\n",
    "\n",
    "# Initialize with XGBoost\n",
    "model_reg3 = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    base_model=CTAXGBoost,  # XGBoost model\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_reg3 = build_features(model_reg3, daily_df, intraday_data)\n",
    "common_idx3 = X_reg3.index.intersection(target_returns.index)\n",
    "X3 = X_reg3.loc[common_idx3]\n",
    "y3 = target_returns.loc[common_idx3]\n",
    "\n",
    "# Same split\n",
    "split_idx3 = int(len(X3) * 0.8)\n",
    "X_train3, X_test3 = X3.iloc[:split_idx3], X3.iloc[split_idx3:]\n",
    "y_train3, y_test3 = y3.iloc[:split_idx3], y3.iloc[split_idx3:]\n",
    "val_size3 = int(len(X_train3) * 0.2)\n",
    "X_val3 = X_train3.iloc[-val_size3:]\n",
    "y_val3 = y_train3.iloc[-val_size3:]\n",
    "X_train_fit3 = X_train3.iloc[:-val_size3]\n",
    "y_train_fit3 = y_train3.iloc[:-val_size3]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(X_train_fit3)} samples\")\n",
    "print(f\"  Val:   {len(X_val3)} samples\")\n",
    "print(f\"  Test:  {len(X_test3)} samples\")\n",
    "\n",
    "# Train XGBoost model\n",
    "print(f\"\\nTraining XGBoost regressor...\")\n",
    "model_reg3.fit_with_grid_search(\n",
    "    X_train_fit3, y_train_fit3,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "metrics_reg3 = model_reg3.evaluate(X_test3, y_test3)\n",
    "print(f\"\\nXGBoost Regression Metrics:\")\n",
    "print(f\"  R²:   {metrics_reg3['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_reg3['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_reg3['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_reg3['directional_accuracy']:.2%}\")"
   ],
   "metadata": {
    "id": "Mahe3mlqbAkw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 4: Random Forest Regressor"
   ],
   "metadata": {
    "id": "M7YQs6yjbAkx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 4: RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with Random Forest\n",
    "model_reg4 = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    base_model=CTARForest\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_reg4 = build_features(model_reg4, daily_df, intraday_data)\n",
    "common_idx4 = X_reg4.index.intersection(target_returns.index)\n",
    "X4 = X_reg4.loc[common_idx4]\n",
    "y4 = target_returns.loc[common_idx4]\n",
    "\n",
    "# Same split\n",
    "split_idx4 = int(len(X4) * 0.8)\n",
    "X_train4, X_test4 = X4.iloc[:split_idx4], X4.iloc[split_idx4:]\n",
    "y_train4, y_test4 = y4.iloc[:split_idx4], y4.iloc[split_idx4:]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(X_train4)} samples\")\n",
    "print(f\"  Test:  {len(X_test4)} samples\")\n",
    "\n",
    "# Train Random Forest model (no early stopping for RF)\n",
    "print(f\"\\nTraining Random Forest regressor...\")\n",
    "model_reg4.fit_with_grid_search(X_train4, y_train4, cv=3)\n",
    "\n",
    "# Evaluate\n",
    "metrics_reg4 = model_reg4.evaluate(X_test4, y_test4)\n",
    "print(f\"\\nRandom Forest Regression Metrics:\")\n",
    "print(f\"  R²:   {metrics_reg4['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_reg4['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_reg4['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_reg4['directional_accuracy']:.2%}\")"
   ],
   "metadata": {
    "id": "-womilEObAkx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "B6MgmBGNGs0w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWz2OD-wbAkx"
   },
   "source": [
    "## Regression Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaE9uQSabAky"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions from models\n",
    "y_pred_reg1 = model_reg1.predict(X_test)\n",
    "y_pred_reg2 = model_reg2.predict(X_test2)\n",
    "y_pred_reg3 = model_reg3.predict(X_test3)\n",
    "y_pred_reg4 = model_reg4.predict(X_test4)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Baseline scatter\n",
    "axes[0, 0].scatter(y_test, y_pred_reg1, alpha=0.6, s=30, label='Predictions', edgecolors='black', linewidth=0.5)\n",
    "# Use data range for perfect line instead of min/max which can be outliers\n",
    "q_low, q_high = y_test.quantile([0.05, 0.95])\n",
    "axes[0, 0].set_xlabel('Actual Returns', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Predicted Returns', fontsize=11)\n",
    "axes[0, 0].set_title(f'Model 1: LightGBM Baseline (R²={metrics_reg1[\"r2\"]:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tuned scatter\n",
    "axes[0, 1].scatter(y_test2, y_pred_reg2, alpha=0.6, s=30, color='green', label='Predictions', edgecolors='black', linewidth=0.5)\n",
    "q_low2, q_high2 = y_test2.quantile([0.05, 0.95])\n",
    "axes[0, 1].set_xlabel('Actual Returns', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Predicted Returns', fontsize=11)\n",
    "axes[0, 1].set_title(f'Model 2: LightGBM Tuned (R²={metrics_reg2[\"r2\"]:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Model comparison bar chart\n",
    "model_names = ['LightGBM\\nBaseline', 'LightGBM\\nTuned', 'XGBoost', 'Random\\nForest']\n",
    "r2_scores = [metrics_reg1['r2'], metrics_reg2['r2'], metrics_reg3['r2'], metrics_reg4['r2']]\n",
    "colors = ['steelblue', 'green', 'orange', 'purple']\n",
    "bars = axes[1, 0].bar(model_names, r2_scores, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_ylabel('R² Score', fontsize=11)\n",
    "axes[1, 0].set_title('Model Performance Comparison (R²)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_ylim([min(r2_scores) - 0.05, max(r2_scores) + 0.05])\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, r2_scores):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{score:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Feature importance (tuned model)\n",
    "top_features = model_reg2.model.get_feature_importance(importance_type='gain', top_n=20)\n",
    "features = list(top_features.keys())\n",
    "importances = list(top_features.values)\n",
    "# Sort by importance\n",
    "sorted_idx = sorted(range(len(importances)), key=lambda k: importances[k])\n",
    "features_sorted = [features[i] for i in sorted_idx]\n",
    "importances_sorted = [importances[i] for i in sorted_idx]\n",
    "axes[1, 1].barh(features_sorted, importances_sorted, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.8)\n",
    "axes[1, 1].set_xlabel('Importance (Gain)', fontsize=11)\n",
    "axes[1, 1].set_title('Top 10 Features - LightGBM Tuned Model', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGuPZbQ1bAky"
   },
   "source": [
    "# Part 2: Classification Models\n",
    "\n",
    "Predict opening period direction (binary) or regime (multiclass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hPV1cNzbAky"
   },
   "source": [
    "## Model 3: Binary Classifier (Up/Down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_kWrtn2bAky"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 3: BINARY CLASSIFIER (UP/DOWN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with binary classification task\n",
    "model_clf_binary = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    base_model=CTALight,\n",
    "    task='binary_classification'\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_clf_bin = build_features(model_clf_binary, daily_df, intraday_data)\n",
    "\n",
    "# Create binary target (0=down, 1=up)\n",
    "y_clf_binary = model_clf_binary.create_clf_target(\n",
    "    n_classes=2,\n",
    "    add_as_feature=False\n",
    ")\n",
    "\n",
    "print(f\"\\nBinary target distribution:\")\n",
    "print(y_clf_binary.value_counts(normalize=True))\n",
    "print(f\"\\nFeatures: {X_clf_bin.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvlJh005bAkz"
   },
   "outputs": [],
   "source": [
    "# Align and split\n",
    "common_idx_bin = X_clf_bin.index.intersection(y_clf_binary.index)\n",
    "X_bin = X_clf_bin.loc[common_idx_bin]\n",
    "y_bin = y_clf_binary.loc[common_idx_bin]\n",
    "\n",
    "split_idx_bin = int(len(X_bin) * 0.8)\n",
    "X_train_bin, X_test_bin = X_bin.iloc[:split_idx_bin], X_bin.iloc[split_idx_bin:]\n",
    "y_train_bin, y_test_bin = y_bin.iloc[:split_idx_bin], y_bin.iloc[split_idx_bin:]\n",
    "\n",
    "val_size_bin = int(len(X_train_bin) * 0.2)\n",
    "X_val_bin = X_train_bin.iloc[-val_size_bin:]\n",
    "y_val_bin = y_train_bin.iloc[-val_size_bin:]\n",
    "X_train_fit_bin = X_train_bin.iloc[:-val_size_bin]\n",
    "y_train_fit_bin = y_train_bin.iloc[:-val_size_bin]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(X_train_fit_bin)} samples\")\n",
    "print(f\"  Val:   {len(X_val_bin)} samples\")\n",
    "print(f\"  Test:  {len(X_test_bin)} samples\")\n",
    "\n",
    "# Train binary classifier\n",
    "print(f\"\\nTraining binary classifier...\")\n",
    "model_clf_binary.fit(\n",
    "    X_train_fit_bin, y_train_fit_bin,\n",
    "    eval_set=(X_val_bin, y_val_bin),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Predict and convert probabilities to class labels\n",
    "# LightGBM binary classification returns probabilities for class 1\n",
    "y_pred_proba_bin = model_clf_binary.predict(X_test_bin)\n",
    "y_pred_bin = (y_pred_proba_bin > 0.5).astype(int)  # Convert to class labels\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(f\"\\nBinary Classification Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"  F1 Score:  {f1_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bin, y_pred_bin, target_names=['Down', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCoTIJ9VbAkz"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_bin = confusion_matrix(y_test_bin, y_pred_bin)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Binary Classification Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZxIZf6CbAk0"
   },
   "source": [
    "## Model 4: Multiclass Classifier (Down/Neutral/Up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRCVAueObAk1"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 4: MULTICLASS CLASSIFIER (DOWN/NEUTRAL/UP)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with multiclass task\n",
    "model_clf_multi = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    supplementary_intraday_data=supplementary,\n",
    "    base_model=CTALight,\n",
    "    task='multiclass',  # Multiclass classification\n",
    "    num_class=3\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_clf_multi = build_features(model_clf_multi, daily_df, intraday_data)\n",
    "\n",
    "# Create multiclass target with thresholds (0=down, 1=neutral, 2=up)\n",
    "# Use 25th and 75th percentiles as thresholds\n",
    "lower_threshold = target_returns.quantile(0.4)\n",
    "upper_threshold = target_returns.quantile(0.6)\n",
    "\n",
    "y_clf_multi = model_clf_multi.create_clf_target(\n",
    "    n_classes=3,\n",
    "    lower_bound=lower_threshold,\n",
    "    upper_bound=upper_threshold,\n",
    "    add_as_feature=False\n",
    ")\n",
    "\n",
    "print(f\"\\nThresholds:\")\n",
    "print(f\"  Lower (25th %ile): {lower_threshold:.6f}\")\n",
    "print(f\"  Upper (75th %ile): {upper_threshold:.6f}\")\n",
    "\n",
    "print(f\"\\nMulticlass target distribution:\")\n",
    "print(y_clf_multi.value_counts(normalize=True).sort_index())\n",
    "print(f\"\\nFeatures: {X_clf_multi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOh_zzWabAk2"
   },
   "outputs": [],
   "source": [
    "# Align and split\n",
    "common_idx_multi = X_clf_multi.index.intersection(y_clf_multi.index)\n",
    "X_multi = X_clf_multi.loc[common_idx_multi]\n",
    "y_multi = y_clf_multi.loc[common_idx_multi]\n",
    "\n",
    "split_idx_multi = int(len(X_multi) * 0.8)\n",
    "X_train_multi, X_test_multi = X_multi.iloc[:split_idx_multi], X_multi.iloc[split_idx_multi:]\n",
    "y_train_multi, y_test_multi = y_multi.iloc[:split_idx_multi], y_multi.iloc[split_idx_multi:]\n",
    "\n",
    "val_size_multi = int(len(X_train_multi) * 0.2)\n",
    "X_val_multi = X_train_multi.iloc[-val_size_multi:]\n",
    "y_val_multi = y_train_multi.iloc[-val_size_multi:]\n",
    "X_train_fit_multi = X_train_multi.iloc[:-val_size_multi]\n",
    "y_train_fit_multi = y_train_multi.iloc[:-val_size_multi]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(X_train_fit_multi)} samples\")\n",
    "print(f\"  Val:   {len(X_val_multi)} samples\")\n",
    "print(f\"  Test:  {len(X_test_multi)} samples\")\n",
    "\n",
    "# Train multiclass classifier\n",
    "print(f\"\\nTraining multiclass classifier...\")\n",
    "model_clf_multi.fit(\n",
    "    X_train_fit_multi, y_train_fit_multi,\n",
    "    eval_set=(X_val_multi, y_val_multi),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Predict and convert probabilities to class labels\n",
    "# LightGBM multiclass returns probabilities for each class\n",
    "y_pred_proba_multi = model_clf_multi.predict(X_test_multi)\n",
    "# For multiclass, predict returns (n_samples, n_classes) probabilities\n",
    "# Use argmax to get the class with highest probability\n",
    "if y_pred_proba_multi.ndim > 1:\n",
    "    y_pred_multi = np.argmax(y_pred_proba_multi, axis=1)\n",
    "else:\n",
    "    # If it returns 1D, it's already class labels\n",
    "    y_pred_multi = y_pred_proba_multi.astype(int)\n",
    "\n",
    "print(f\"\\nMulticlass Classification Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test_multi, y_pred_multi):.4f}\")\n",
    "print(f\"  Macro F1: {f1_score(y_test_multi, y_pred_multi, average='macro'):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_multi, y_pred_multi,\n",
    "                          target_names=['Down', 'Neutral', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYUakjhybAk2"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_multi = confusion_matrix(y_test_multi, y_pred_multi)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Down', 'Neutral', 'Up'],\n",
    "            yticklabels=['Down', 'Neutral', 'Up'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Multiclass Classification Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0Vc6tndbAk2"
   },
   "source": [
    "## Classification Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGJ37_HhbAk2"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Binary classifier features\n",
    "top_bin = model_clf_binary.model.get_feature_importance(importance_type='gain', top_n=20)\n",
    "features_bin = list(top_bin.keys())\n",
    "importances_bin = list(top_bin.values)\n",
    "# Sort by importance\n",
    "sorted_idx_bin = sorted(range(len(importances_bin)), key=lambda k: importances_bin[k])\n",
    "features_bin_sorted = [features_bin[i] for i in sorted_idx_bin]\n",
    "importances_bin_sorted = [importances_bin[i] for i in sorted_idx_bin]\n",
    "axes[0].barh(features_bin_sorted, importances_bin_sorted, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.8)\n",
    "axes[0].set_xlabel('Importance (Gain)', fontsize=11)\n",
    "axes[0].set_title('Top 10 Features - Binary Classifier', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Multiclass classifier features\n",
    "top_multi = model_clf_multi.model.get_feature_importance(importance_type='gain', top_n=25)\n",
    "features_multi = list(top_multi.keys())\n",
    "importances_multi = list(top_multi.values)\n",
    "# Sort by importance\n",
    "sorted_idx_multi = sorted(range(len(importances_multi)), key=lambda k: importances_multi[k])\n",
    "features_multi_sorted = [features_multi[i] for i in sorted_idx_multi]\n",
    "importances_multi_sorted = [importances_multi[i] for i in sorted_idx_multi]\n",
    "axes[1].barh(features_multi_sorted, importances_multi_sorted, color='green', alpha=0.7, edgecolor='black', linewidth=0.8)\n",
    "axes[1].set_xlabel('Importance (Gain)', fontsize=11)\n",
    "axes[1].set_title('Top 10 Features - Multiclass Classifier', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIZR2DzPbAk3"
   },
   "source": [
    "# Summary: Model Comparison\n",
    "\n",
    "Comparison of all models across regression and classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VFJM8HFbAk3"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nREGRESSION MODELS:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model 1 (LightGBM Baseline): R² = {metrics_reg1['r2']:.4f}, RMSE = {metrics_reg1['rmse']:.6f}\")\n",
    "print(f\"Model 2 (LightGBM Tuned):    R² = {metrics_reg2['r2']:.4f}, RMSE = {metrics_reg2['rmse']:.6f}\")\n",
    "print(f\"Model 3 (XGBoost):           R² = {metrics_reg3['r2']:.4f}, RMSE = {metrics_reg3['rmse']:.6f}\")\n",
    "print(f\"Model 4 (Random Forest):     R² = {metrics_reg4['r2']:.4f}, RMSE = {metrics_reg4['rmse']:.6f}\")\n",
    "\n",
    "print(\"\\nCLASSIFICATION MODELS:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model 5 (Binary):            Accuracy = {accuracy_score(y_test_bin, y_pred_bin):.4f}, F1 = {f1_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"Model 6 (Multiclass):        Accuracy = {accuracy_score(y_test_multi, y_pred_multi):.4f}, F1 = {f1_score(y_test_multi, y_pred_multi, average='macro'):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"✓ Target data uses model.target_data to ensure consistency and avoid lookahead bias\")\n",
    "print(\"✓ IntradayMomentum supports multiple base models (LightGBM, XGBoost, RandomForest)\")\n",
    "print(\"✓ Feature engineering is model-agnostic (same features for all models)\")\n",
    "print(\"✓ Grid search can improve LightGBM regression performance\")\n",
    "print(\"✓ Different models show varying prediction accuracy - compare R² and RMSE\")\n",
    "print(\"✓ Binary and multiclass classification achieve reasonable directional accuracy\")\n",
    "print(\"✓ All models properly handle temporal splits to avoid lookahead bias\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models for Opening Returns Prediction\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Temporal Convolutional Network (TCN)** - Causal convolutions for time series\n",
    "2. **GRU with Attention** - Recurrent network with attention mechanism\n",
    "3. **Model Comparison** - Compare deep learning models with traditional ML baselines\n",
    "\n",
    "**Features Used:**\n",
    "- Short-term daily momentum (1d, 10d, 20d) - properly lagged\n",
    "- HAR-style realized volatility (1d, 5d)\n",
    "- Garman-Klass volatility (5d, 10d, 20d)\n",
    "- Volatility ratios (short/long term)\n",
    "- Previous session levels (high/low/close distances)\n",
    "- Overnight returns, VWAP distance, intraday range\n",
    "- Target time returns and volumes\n",
    "- Cross-asset correlations\n",
    "\n",
    "**Target**: Returns during the opening period (session returns)\n",
    "\n",
    "**Deep Learning Approach**:\n",
    "- Uses sliding windows of historical features (default: 20 days lookback)\n",
    "- Temporal models capture sequential dependencies\n",
    "- Automatic feature extraction through neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import time, timedelta\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CTAFlow imports\n",
    "from CTAFlow.models.intraday_momentum import IntradayMomentum\n",
    "from CTAFlow.models.base_models import CTALight\n",
    "from CTAFlow.models.deep_learning import (\n",
    "    TCNRegressor,\n",
    "    GRUAttnRegressor,\n",
    "    fit,\n",
    "    evaluate,\n",
    "    convert_IM,\n",
    "    TrainConfig,\n",
    "    default_regression_metrics\n",
    ")\n",
    "from CTAFlow.data import read_exported_df\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"✓ Using device: {device}\")\n",
    "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
    "print(f\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SESSION CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Session timing parameters\n",
    "SESSION_START = time(hour=8, minute=30)\n",
    "SESSION_END = time(hour=15, minute=0)\n",
    "CLOSING_LENGTH = timedelta(minutes=60)\n",
    "TIMEZONE = \"America/New_York\"\n",
    "\n",
    "# Feature engineering time parameters\n",
    "KEY_RETURN_TIMES = [time(9, 30), time(14, 0)]\n",
    "OPENING_VOL_PERIOD = timedelta(minutes=60)\n",
    "TARGET_PERIOD = timedelta(hours=6, minutes=30)  # Full session\n",
    "\n",
    "# Deep learning specific configuration\n",
    "LOOKBACK_PERIOD = 20  # Number of days to look back for temporal models\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 2e-3\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "# Data split\n",
    "TRAIN_SPLIT = 0.7  # 70% train\n",
    "VAL_SPLIT = 0.15   # 15% validation\n",
    "TEST_SPLIT = 0.15  # 15% test\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Session: {SESSION_START} to {SESSION_END}\")\n",
    "print(f\"Lookback period: {LOOKBACK_PERIOD} days\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Data split: {TRAIN_SPLIT:.0%} train / {VAL_SPLIT:.0%} val / {TEST_SPLIT:.0%} test\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your ticker and data path\n",
    "TICKER = \"ES\"  # Change to your ticker\n",
    "DATA_PATH = Path(\"path/to/your/data\")  # Update this path\n",
    "\n",
    "# Load intraday data\n",
    "csv_path = DATA_PATH / f\"{TICKER}_5min.csv\"\n",
    "print(f\"Loading {TICKER} from {csv_path}\")\n",
    "\n",
    "intraday_data = read_exported_df(csv_path)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(intraday_data):,} bars\")\n",
    "print(f\"✓ Date range: {intraday_data.index[0].date()} to {intraday_data.index[-1].date()}\")\n",
    "print(f\"\\nData preview:\")\n",
    "intraday_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load supplementary data for cross-asset features\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# SUPPLEMENTARY_TICKERS = [\"NQ\", \"YM\"]  # Related instruments\n",
    "# supplementary_data = {\n",
    "#     ticker: read_exported_df(DATA_PATH / f\"{ticker}_5min.csv\")\n",
    "#     for ticker in SUPPLEMENTARY_TICKERS\n",
    "# }\n",
    "# print(f\"✓ Loaded {len(supplementary_data)} supplementary instruments\")\n",
    "\n",
    "supplementary_data = None  # Set to None if not using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_daily_data(intraday_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create daily OHLC data from intraday bars.\"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "\n",
    "    daily = intraday_df.resample('1D').agg({\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    }).dropna()\n",
    "\n",
    "    return daily\n",
    "\n",
    "\n",
    "def build_features(model, daily_df, intraday_data):\n",
    "    \"\"\"Build comprehensive feature set for deep learning models.\n",
    "    \n",
    "    Creates the same features as the tree-based models notebook,\n",
    "    but formatted for temporal sequence modeling.\n",
    "    \"\"\"\n",
    "    model.training_data = pd.DataFrame(index=daily_df.index)\n",
    "\n",
    "    # Daily momentum features (lagged)\n",
    "    model.add_daily_momentum_features(daily_df, lookbacks=(1, 10, 20))\n",
    "\n",
    "    # HAR volatility features\n",
    "    model.har_volatility_features(intraday_df=intraday_data, horizons=(1, 5))\n",
    "\n",
    "    # Opening range volatility\n",
    "    model.opening_range_volatility(\n",
    "        intraday_df=intraday_data,\n",
    "        period_length=OPENING_VOL_PERIOD,\n",
    "    )\n",
    "\n",
    "    # Garman-Klass volatility\n",
    "    model.gk_vol(intraday_df=intraday_data, lookbacks=(5, 10, 20), add_as_feature=True)\n",
    "\n",
    "    # Volatility ratios\n",
    "    model.vol_ratios(\n",
    "        intraday_df=intraday_data,\n",
    "        short_long_pairs=((5, 20), (10, 60)),\n",
    "        add_as_feature=True\n",
    "    )\n",
    "\n",
    "    # Session end start time for features\n",
    "    session_end_start = KEY_RETURN_TIMES[-1]\n",
    "\n",
    "    # Previous session levels\n",
    "    model.prev_hl(target_time=session_end_start, intraday_df=intraday_data, add_as_feature=True)\n",
    "\n",
    "    # Overnight returns\n",
    "    model.overnight_returns(intraday_df=intraday_data, add_as_feature=True)\n",
    "\n",
    "    # VWAP distance\n",
    "    model.vwap_distance(target_time=KEY_RETURN_TIMES, intraday_df=intraday_data, add_as_feature=True)\n",
    "\n",
    "    # Intraday range\n",
    "    model.intraday_range(\n",
    "        target_time=session_end_start,\n",
    "        intraday_df=intraday_data,\n",
    "        lookback_days=20,\n",
    "        add_as_feature=True\n",
    "    )\n",
    "\n",
    "    # Target time returns\n",
    "    model.target_time_returns(\n",
    "        session_end_start,\n",
    "        period_length=TARGET_PERIOD,\n",
    "        add_as_feature=True\n",
    "    )\n",
    "\n",
    "    model.target_time_returns(\n",
    "        KEY_RETURN_TIMES,\n",
    "        period_length=timedelta(minutes=60),\n",
    "        add_as_feature=True\n",
    "    )\n",
    "\n",
    "    # Target volumes\n",
    "    model.target_time_volume(\n",
    "        session_end_start,\n",
    "        period_length=TARGET_PERIOD,\n",
    "        add_as_feature=True\n",
    "    )\n",
    "\n",
    "    model.target_time_volume(\n",
    "        KEY_RETURN_TIMES,\n",
    "        period_length=timedelta(minutes=60),\n",
    "        add_as_feature=True\n",
    "    )\n",
    "\n",
    "    # Bid-ask imbalance (with proxy)\n",
    "    try:\n",
    "        model.bid_ask_volume_imbalance(\n",
    "            target_time=session_end_start,\n",
    "            intraday_df=intraday_data,\n",
    "            use_proxy=True,\n",
    "            add_as_feature=True\n",
    "        )\n",
    "    except KeyError:\n",
    "        print(\"Note: Bid/ask imbalance features skipped\")\n",
    "\n",
    "    print(f\"\\n✓ Feature engineering complete\")\n",
    "    print(f\"  Total features: {len(model.feature_names)}\")\n",
    "    print(f\"  Training data shape: {model.training_data.shape}\")\n",
    "    return model.training_data\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IntradayMomentum model\n",
    "model = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    base_model=CTALight,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary_data,\n",
    "    use_gpu=False  # Not needed for feature engineering\n",
    ")\n",
    "\n",
    "# Use pre-calculated target returns\n",
    "target_returns = model.target_data\n",
    "\n",
    "# Prepare daily data\n",
    "daily_df = prepare_daily_data(intraday_data)\n",
    "\n",
    "print(f\"✓ Daily data: {len(daily_df)} days\")\n",
    "print(f\"✓ Target returns: {len(target_returns)} days\")\n",
    "print(f\"\\nTarget Statistics:\")\n",
    "print(f\"  Mean: {target_returns.mean():.6f}\")\n",
    "print(f\"  Std:  {target_returns.std():.6f}\")\n",
    "print(f\"  Min:  {target_returns.min():.6f}\")\n",
    "print(f\"  Max:  {target_returns.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features\n",
    "X = build_features(model, daily_df, intraday_data)\n",
    "\n",
    "# Align features and target\n",
    "common_idx = X.index.intersection(target_returns.index)\n",
    "X = X.loc[common_idx]\n",
    "y = target_returns.loc[common_idx]\n",
    "\n",
    "print(f\"\\n✓ Aligned data: {len(X)} samples, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to window datasets for deep learning\n",
    "# This creates sliding windows of historical data\n",
    "(train_ds, train_dl), (val_ds, val_dl) = convert_IM(\n",
    "    model,\n",
    "    lookback_period=LOOKBACK_PERIOD,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    val_split=True,\n",
    "    val_size=VAL_SPLIT / (TRAIN_SPLIT + VAL_SPLIT)  # Adjust for train+val only\n",
    ")\n",
    "\n",
    "# Create separate test set\n",
    "test_idx = int(len(X) * (TRAIN_SPLIT + VAL_SPLIT))\n",
    "from CTAFlow.data import make_window_dataset\n",
    "\n",
    "test_ds, test_dl = make_window_dataset(\n",
    "    X.iloc[test_idx:],\n",
    "    y.iloc[test_idx:],\n",
    "    lookback=LOOKBACK_PERIOD,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Dataset creation complete\")\n",
    "print(f\"  Train batches: {len(train_dl)}\")\n",
    "print(f\"  Val batches:   {len(val_dl)}\")\n",
    "print(f\"  Test batches:  {len(test_dl)}\")\n",
    "print(f\"  Input shape per sample: (features={X.shape[1]}, lookback={LOOKBACK_PERIOD})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Temporal Convolutional Network (TCN)\n",
    "\n",
    "TCN uses causal (non-leaking) convolutions with dilations to capture long-range dependencies.\n",
    "- **Pros**: Parallelizable, stable gradients, long effective receptive field\n",
    "- **Cons**: Less interpretable than tree models, requires more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: TEMPORAL CONVOLUTIONAL NETWORK (TCN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create TCN model\n",
    "tcn_model = TCNRegressor(\n",
    "    in_channels=X.shape[1],  # Number of features\n",
    "    channels=(64, 64, 64),   # Hidden layer sizes\n",
    "    kernel_size=3,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(tcn_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in tcn_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "tcn_config = TrainConfig(\n",
    "    epochs=EPOCHS,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-3,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=True,  # Automatic mixed precision for faster training\n",
    "    device=device,\n",
    "    log_every=10,\n",
    "    early_stop_patience=20,\n",
    "    early_stop_min_delta=1e-5,\n",
    "    scheduler=\"plateau\",\n",
    "    plateau_patience=5,\n",
    "    plateau_factor=0.5\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.HuberLoss(delta=1.0)  # Robust to outliers\n",
    "\n",
    "print(\"\\nTraining TCN model...\")\n",
    "print(f\"Configuration: {tcn_config}\")\n",
    "\n",
    "# Train model\n",
    "tcn_model, tcn_history = fit(\n",
    "    model=tcn_model,\n",
    "    train_loader=train_dl,\n",
    "    val_loader=val_dl,\n",
    "    loss_fn=loss_fn,\n",
    "    cfg=tcn_config,\n",
    "    metrics_fn=default_regression_metrics\n",
    ")\n",
    "\n",
    "print(\"\\n✓ TCN training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate TCN on test set\n",
    "tcn_metrics = evaluate(\n",
    "    model=tcn_model,\n",
    "    loader=test_dl,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    metrics_fn=default_regression_metrics,\n",
    "    use_amp=tcn_config.use_amp\n",
    ")\n",
    "\n",
    "print(\"\\nTCN Test Metrics:\")\n",
    "print(f\"  Loss (Huber): {tcn_metrics['loss']:.6f}\")\n",
    "print(f\"  MSE:          {tcn_metrics['mse']:.6f}\")\n",
    "print(f\"  MAE:          {tcn_metrics['mae']:.6f}\")\n",
    "print(f\"  Correlation:  {tcn_metrics['corr']:.4f}\")\n",
    "print(f\"  Dir Accuracy: {tcn_metrics['dir_acc']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: GRU with Attention\n",
    "\n",
    "GRU (Gated Recurrent Unit) with attention mechanism to focus on important time steps.\n",
    "- **Pros**: Captures sequential dependencies, attention provides interpretability\n",
    "- **Cons**: Sequential processing (slower), can have vanishing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: GRU WITH ATTENTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create GRU model\n",
    "gru_model = GRUAttnRegressor(\n",
    "    in_channels=X.shape[1],  # Number of features\n",
    "    hidden=128,              # Hidden state size\n",
    "    layers=2,                # Number of GRU layers\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(gru_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in gru_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (same as TCN)\n",
    "gru_config = TrainConfig(\n",
    "    epochs=EPOCHS,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-3,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=True,\n",
    "    device=device,\n",
    "    log_every=10,\n",
    "    early_stop_patience=20,\n",
    "    early_stop_min_delta=1e-5,\n",
    "    scheduler=\"plateau\",\n",
    "    plateau_patience=5,\n",
    "    plateau_factor=0.5\n",
    ")\n",
    "\n",
    "print(\"\\nTraining GRU model...\")\n",
    "\n",
    "# Train model\n",
    "gru_model, gru_history = fit(\n",
    "    model=gru_model,\n",
    "    train_loader=train_dl,\n",
    "    val_loader=val_dl,\n",
    "    loss_fn=loss_fn,\n",
    "    cfg=gru_config,\n",
    "    metrics_fn=default_regression_metrics\n",
    ")\n",
    "\n",
    "print(\"\\n✓ GRU training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate GRU on test set\n",
    "gru_metrics = evaluate(\n",
    "    model=gru_model,\n",
    "    loader=test_dl,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    metrics_fn=default_regression_metrics,\n",
    "    use_amp=gru_config.use_amp\n",
    ")\n",
    "\n",
    "print(\"\\nGRU Test Metrics:\")\n",
    "print(f\"  Loss (Huber): {gru_metrics['loss']:.6f}\")\n",
    "print(f\"  MSE:          {gru_metrics['mse']:.6f}\")\n",
    "print(f\"  MAE:          {gru_metrics['mae']:.6f}\")\n",
    "print(f\"  Correlation:  {gru_metrics['corr']:.4f}\")\n",
    "print(f\"  Dir Accuracy: {gru_metrics['dir_acc']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: LightGBM for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BASELINE: LIGHTGBM REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create baseline LightGBM model for comparison\n",
    "lgbm_model = IntradayMomentum(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=SESSION_START,\n",
    "    session_end=SESSION_END,\n",
    "    closing_length=CLOSING_LENGTH,\n",
    "    tz=TIMEZONE,\n",
    "    base_model=CTALight,\n",
    "    task='regression',\n",
    "    supplementary_intraday_data=supplementary_data,\n",
    "    use_gpu=False\n",
    ")\n",
    "\n",
    "# Build features (same as deep learning models)\n",
    "X_lgbm = build_features(lgbm_model, daily_df, intraday_data)\n",
    "common_idx_lgbm = X_lgbm.index.intersection(target_returns.index)\n",
    "X_lgbm = X_lgbm.loc[common_idx_lgbm]\n",
    "y_lgbm = target_returns.loc[common_idx_lgbm]\n",
    "\n",
    "# Use same split as deep learning models\n",
    "train_val_idx = int(len(X_lgbm) * (TRAIN_SPLIT + VAL_SPLIT))\n",
    "val_idx = int(len(X_lgbm) * TRAIN_SPLIT)\n",
    "\n",
    "X_train_lgbm = X_lgbm.iloc[:val_idx]\n",
    "y_train_lgbm = y_lgbm.iloc[:val_idx]\n",
    "X_val_lgbm = X_lgbm.iloc[val_idx:train_val_idx]\n",
    "y_val_lgbm = y_lgbm.iloc[val_idx:train_val_idx]\n",
    "X_test_lgbm = X_lgbm.iloc[train_val_idx:]\n",
    "y_test_lgbm = y_lgbm.iloc[train_val_idx:]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Train: {len(X_train_lgbm)} samples\")\n",
    "print(f\"  Val:   {len(X_val_lgbm)} samples\")\n",
    "print(f\"  Test:  {len(X_test_lgbm)} samples\")\n",
    "\n",
    "# Train LightGBM\n",
    "print(f\"\\nTraining LightGBM...\")\n",
    "lgbm_model.fit(\n",
    "    X_train_lgbm, y_train_lgbm,\n",
    "    eval_set=(X_val_lgbm, y_val_lgbm),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=500\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "lgbm_metrics = lgbm_model.evaluate(X_test_lgbm, y_test_lgbm)\n",
    "\n",
    "print(\"\\nLightGBM Test Metrics:\")\n",
    "print(f\"  R²:           {lgbm_metrics['r2']:.4f}\")\n",
    "print(f\"  RMSE:         {lgbm_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:          {lgbm_metrics['mae']:.6f}\")\n",
    "print(f\"  Dir Accuracy: {lgbm_metrics['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# TCN training history\n",
    "tcn_train_loss = [m['loss'] for m in tcn_history['train']]\n",
    "tcn_val_loss = [m['loss'] for m in tcn_history['val']]\n",
    "axes[0].plot(tcn_train_loss, label='Train Loss', linewidth=2)\n",
    "axes[0].plot(tcn_val_loss, label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0].set_ylabel('Loss (Huber)', fontsize=11)\n",
    "axes[0].set_title('TCN Training History', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# GRU training history\n",
    "gru_train_loss = [m['loss'] for m in gru_history['train']]\n",
    "gru_val_loss = [m['loss'] for m in gru_history['val']]\n",
    "axes[1].plot(gru_train_loss, label='Train Loss', linewidth=2, color='green')\n",
    "axes[1].plot(gru_val_loss, label='Val Loss', linewidth=2, color='orange')\n",
    "axes[1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1].set_ylabel('Loss (Huber)', fontsize=11)\n",
    "axes[1].set_title('GRU Training History', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from all models\n",
    "tcn_model.eval()\n",
    "gru_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    tcn_preds = []\n",
    "    gru_preds = []\n",
    "    test_targets = []\n",
    "    \n",
    "    for xb, yb in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        tcn_preds.append(tcn_model(xb).cpu().numpy())\n",
    "        gru_preds.append(gru_model(xb).cpu().numpy())\n",
    "        test_targets.append(yb.numpy())\n",
    "    \n",
    "    tcn_preds = np.concatenate(tcn_preds)\n",
    "    gru_preds = np.concatenate(gru_preds)\n",
    "    test_targets = np.concatenate(test_targets)\n",
    "\n",
    "lgbm_preds = lgbm_model.predict(X_test_lgbm).values\n",
    "\n",
    "print(\"✓ Predictions generated for all models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# TCN scatter plot\n",
    "axes[0, 0].scatter(test_targets, tcn_preds, alpha=0.6, s=30, label='Predictions', edgecolors='black', linewidth=0.5)\n",
    "axes[0, 0].plot([test_targets.min(), test_targets.max()], [test_targets.min(), test_targets.max()], \n",
    "                'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Actual Returns', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Predicted Returns', fontsize=11)\n",
    "axes[0, 0].set_title(f'TCN (Corr={tcn_metrics[\"corr\"]:.4f}, Dir Acc={tcn_metrics[\"dir_acc\"]:.2%})', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# GRU scatter plot\n",
    "axes[0, 1].scatter(test_targets, gru_preds, alpha=0.6, s=30, color='green', label='Predictions', \n",
    "                   edgecolors='black', linewidth=0.5)\n",
    "axes[0, 1].plot([test_targets.min(), test_targets.max()], [test_targets.min(), test_targets.max()], \n",
    "                'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 1].set_xlabel('Actual Returns', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Predicted Returns', fontsize=11)\n",
    "axes[0, 1].set_title(f'GRU (Corr={gru_metrics[\"corr\"]:.4f}, Dir Acc={gru_metrics[\"dir_acc\"]:.2%})', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Performance comparison bar chart\n",
    "model_names = ['TCN', 'GRU', 'LightGBM']\n",
    "correlations = [tcn_metrics['corr'], gru_metrics['corr'], \n",
    "                np.corrcoef(test_targets[:len(lgbm_preds)], lgbm_preds)[0, 1]]\n",
    "colors = ['steelblue', 'green', 'orange']\n",
    "bars = axes[1, 0].bar(model_names, correlations, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_ylabel('Correlation', fontsize=11)\n",
    "axes[1, 0].set_title('Model Performance Comparison (Correlation)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_ylim([0, max(correlations) * 1.2])\n",
    "for bar, corr in zip(bars, correlations):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{corr:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Directional accuracy comparison\n",
    "dir_accs = [tcn_metrics['dir_acc'], gru_metrics['dir_acc'], lgbm_metrics['directional_accuracy']]\n",
    "bars2 = axes[1, 1].bar(model_names, dir_accs, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_ylabel('Directional Accuracy', fontsize=11)\n",
    "axes[1, 1].set_title('Model Performance Comparison (Direction)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "axes[1, 1].axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Random (50%)')\n",
    "for bar, acc in zip(bars2, dir_accs):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acc:.2%}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nDEEP LEARNING MODELS:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"TCN:\")\n",
    "print(f\"  MSE:          {tcn_metrics['mse']:.6f}\")\n",
    "print(f\"  MAE:          {tcn_metrics['mae']:.6f}\")\n",
    "print(f\"  Correlation:  {tcn_metrics['corr']:.4f}\")\n",
    "print(f\"  Dir Accuracy: {tcn_metrics['dir_acc']:.2%}\")\n",
    "\n",
    "print(f\"\\nGRU with Attention:\")\n",
    "print(f\"  MSE:          {gru_metrics['mse']:.6f}\")\n",
    "print(f\"  MAE:          {gru_metrics['mae']:.6f}\")\n",
    "print(f\"  Correlation:  {gru_metrics['corr']:.4f}\")\n",
    "print(f\"  Dir Accuracy: {gru_metrics['dir_acc']:.2%}\")\n",
    "\n",
    "print(\"\\nBASELINE MODEL:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"LightGBM:\")\n",
    "print(f\"  R²:           {lgbm_metrics['r2']:.4f}\")\n",
    "print(f\"  RMSE:         {lgbm_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE:          {lgbm_metrics['mae']:.6f}\")\n",
    "print(f\"  Dir Accuracy: {lgbm_metrics['directional_accuracy']:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"✓ Deep learning models capture temporal dependencies through sequence modeling\")\n",
    "print(\"✓ TCN uses causal convolutions - parallelizable and stable\")\n",
    "print(\"✓ GRU with attention - sequential processing with interpretable attention weights\")\n",
    "print(\"✓ Both models use sliding windows of historical features (lookback period)\")\n",
    "print(\"✓ Compare correlation and directional accuracy across all models\")\n",
    "print(\"✓ Deep learning models may require more data and tuning than tree-based models\")\n",
    "print(\"✓ Consider ensemble approaches combining deep learning and tree-based models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Experiment with different architectures (more layers, hidden units)\")\n",
    "print(\"2. Try different lookback periods (10, 30, 60 days)\")\n",
    "print(\"3. Add regularization techniques (dropout, weight decay, early stopping)\")\n",
    "print(\"4. Implement ensemble methods combining multiple models\")\n",
    "print(\"5. Add feature engineering specific to sequential data (technical indicators)\")\n",
    "print(\"6. Explore other architectures (LSTM, Transformer, hybrid models)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "save_path = Path(\"./saved_models\")\n",
    "save_path.mkdir(exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': tcn_model.state_dict(),\n",
    "    'config': tcn_config,\n",
    "    'metrics': tcn_metrics,\n",
    "    'feature_names': model.feature_names,\n",
    "}, save_path / 'tcn_model.pt')\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': gru_model.state_dict(),\n",
    "    'config': gru_config,\n",
    "    'metrics': gru_metrics,\n",
    "    'feature_names': model.feature_names,\n",
    "}, save_path / 'gru_model.pt')\n",
    "\n",
    "print(f\"✓ Models saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

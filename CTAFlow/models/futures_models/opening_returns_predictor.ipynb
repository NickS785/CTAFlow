{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Returns Prediction with IntradayMomentumLight\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Regression Models** - LightGBM, XGBoost, and Random Forest\n",
    "2. **Classification Models** - Binary and multiclass LightGBM classifiers\n",
    "3. **Model Comparison** - Performance across different algorithms\n",
    "\n",
    "**Features Used:**\n",
    "- Short-term daily momentum (1d, 5d, 10d, 20d) - properly lagged\n",
    "- HAR-style realized volatility (1d, 5d, 22d)\n",
    "- Opening range volatility (first 60 minutes)\n",
    "- Previous high/low features (5-day)\n",
    "\n",
    "**Target**: Returns during the opening period (first 60 minutes of session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import time, timedelta\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Add parent directories to path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from CTAFlow.models.intraday_momentum import IntradayMomentumLight\n",
    "from CTAFlow.models.base_models import CTALight, CTAXGBoost, CTARForest\n",
    "from CTAFlow.config import INTRADAY_DATA_PATH\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"✓ Imports successful\")\n",
    "print(f\"✓ Data path: {INTRADAY_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_opening_returns(\n",
    "    intraday_df: pd.DataFrame,\n",
    "    session_open: time = time(8, 30),\n",
    "    opening_window: timedelta = timedelta(minutes=60),\n",
    "    price_col: str = \"Close\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate daily returns during the opening period.\"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "    \n",
    "    work_df = pd.DataFrame({'price': intraday_df[price_col]})\n",
    "    work_df['date'] = work_df.index.normalize()\n",
    "    \n",
    "    session_open_offset = pd.Timedelta(hours=session_open.hour, minutes=session_open.minute)\n",
    "    work_df['session_start'] = work_df['date'] + session_open_offset\n",
    "    work_df['session_end'] = work_df['session_start'] + opening_window\n",
    "    \n",
    "    opening_mask = work_df.index >= work_df['session_start']\n",
    "    opening_data = work_df[opening_mask].groupby('date')['price'].first()\n",
    "    \n",
    "    closing_mask = (work_df.index >= work_df['session_start']) & (work_df.index < work_df['session_end'])\n",
    "    closing_data = work_df[closing_mask].groupby('date')['price'].last()\n",
    "    \n",
    "    opening_returns = np.log(closing_data / opening_data)\n",
    "    return opening_returns\n",
    "\n",
    "\n",
    "def prepare_daily_data(intraday_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create daily OHLC data from intraday bars.\"\"\"\n",
    "    if not isinstance(intraday_df.index, pd.DatetimeIndex):\n",
    "        intraday_df.index = pd.to_datetime(intraday_df.index)\n",
    "    \n",
    "    daily = intraday_df.resample('1D').agg({\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    }).dropna()\n",
    "    \n",
    "    return daily\n",
    "\n",
    "\n",
    "def build_features(model, daily_df, intraday_data):\n",
    "    \"\"\"Build comprehensive feature set for the model.\"\"\"\n",
    "    model.training_data = pd.DataFrame(index=daily_df.index)\n",
    "    \n",
    "    # Daily momentum features (lagged)\n",
    "    momentum_feats = model.add_daily_momentum_features(\n",
    "        daily_df,\n",
    "        lookbacks=(1, 5, 10, 20)\n",
    "    )\n",
    "    \n",
    "    # HAR volatility features\n",
    "    har_feats = model.har_volatility_features(\n",
    "        intraday_df=intraday_data,\n",
    "        horizons=(1, 5, 22)\n",
    "    )\n",
    "    \n",
    "    # Opening range volatility\n",
    "    opening_vol = model.opening_range_volatility(\n",
    "        intraday_df=intraday_data,\n",
    "        period_length=timedelta(minutes=60)\n",
    "    )\n",
    "    \n",
    "    # Previous high/low features\n",
    "    prev_hl_feats = model.prev_hl(horizon=5, add_as_feature=False, normalize=True)\n",
    "    prev_hl_df = pd.DataFrame({\n",
    "        '5_high': prev_hl_feats[0],\n",
    "        '5_low': prev_hl_feats[1]\n",
    "    })\n",
    "    \n",
    "    # Combine all features\n",
    "    model.training_data = pd.concat(\n",
    "        [momentum_feats, har_feats, opening_vol, prev_hl_df], \n",
    "        axis=1\n",
    "    ).dropna()\n",
    "    \n",
    "    return model.training_data\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"PL\"  # Platinum futures\n",
    "\n",
    "# Load intraday data from CSV\n",
    "csv_path = INTRADAY_DATA_PATH / f\"CSV/{ticker}_5min.csv\"\n",
    "print(f\"Loading {ticker} from {csv_path}\")\n",
    "\n",
    "intraday_data = pd.read_csv(csv_path, parse_dates=['timestamp'])\n",
    "intraday_data.set_index('timestamp', inplace=True)\n",
    "intraday_data.sort_index(inplace=True)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(intraday_data):,} bars\")\n",
    "print(f\"✓ Date range: {intraday_data.index[0].date()} to {intraday_data.index[-1].date()}\")\n",
    "print(f\"\\nData preview:\")\n",
    "intraday_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Daily Data and Calculate Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = prepare_daily_data(intraday_data)\n",
    "target_returns = calculate_opening_returns(intraday_data)\n",
    "\n",
    "print(f\"✓ Daily data: {len(daily_df)} days\")\n",
    "print(f\"✓ Target returns: {len(target_returns)} days\")\n",
    "print(f\"\\nTarget Statistics:\")\n",
    "print(f\"  Mean: {target_returns.mean():.6f}\")\n",
    "print(f\"  Std:  {target_returns.std():.6f}\")\n",
    "print(f\"  Min:  {target_returns.min():.6f}\")\n",
    "print(f\"  Max:  {target_returns.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Regression Models\n",
    "\n",
    "Compare LightGBM, XGBoost, and Random Forest for continuous return prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Baseline LightGBM Regressor (CTALight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: BASELINE LIGHTGBM REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with CTALight\n",
    "model_lgb = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTALight,\n",
    "    task='regression'\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_lgb = build_features(model_lgb, daily_df, intraday_data)\n",
    "print(f\"\\nFeatures built: {X_lgb.shape}\")\n",
    "\n",
    "# Align and split\n",
    "common_idx = X_lgb.index.intersection(target_returns.index)\n",
    "X = X_lgb.loc[common_idx]\n",
    "y = target_returns.loc[common_idx]\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "val_size = int(len(X_train) * 0.2)\n",
    "X_val = X_train.iloc[-val_size:]\n",
    "y_val = y_train.iloc[-val_size:]\n",
    "X_train_fit = X_train.iloc[:-val_size]\n",
    "y_train_fit = y_train.iloc[:-val_size]\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train_fit)} samples\")\n",
    "print(f\"  Val:   {len(X_val)} samples\")\n",
    "print(f\"  Test:  {len(X_test)} samples\")\n",
    "\n",
    "# Train\n",
    "print(f\"\\nTraining LightGBM...\")\n",
    "model_lgb.fit(\n",
    "    X_train_fit, y_train_fit,\n",
    "    eval_set=(X_val, y_val),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "metrics_lgb = model_lgb.evaluate(X_test, y_test)\n",
    "print(f\"\\nLightGBM Metrics:\")\n",
    "print(f\"  R²:   {metrics_lgb['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_lgb['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_lgb['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_lgb['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost Regressor (CTAXGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 2: XGBOOST REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with CTAXGBoost\n",
    "model_xgb = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTAXGBoost\n",
    ")\n",
    "\n",
    "# Build features (reuse same data)\n",
    "X_xgb = build_features(model_xgb, daily_df, intraday_data)\n",
    "\n",
    "# Train\n",
    "print(f\"\\nTraining XGBoost...\")\n",
    "model_xgb.fit(\n",
    "    X_train_fit, y_train_fit,\n",
    "    eval_set=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "metrics_xgb = model_xgb.evaluate(X_test, y_test)\n",
    "print(f\"\\nXGBoost Metrics:\")\n",
    "print(f\"  R²:   {metrics_xgb['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_xgb['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_xgb['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_xgb['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest Regressor (CTARForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 3: RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with CTARForest\n",
    "model_rf = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTARForest\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_rf = build_features(model_rf, daily_df, intraday_data)\n",
    "\n",
    "# Train\n",
    "print(f\"\\nTraining Random Forest...\")\n",
    "model_rf.fit(\n",
    "    X_train_fit, y_train_fit,\n",
    "    eval_set=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "metrics_rf = model_rf.evaluate(X_test, y_test)\n",
    "print(f\"\\nRandom Forest Metrics:\")\n",
    "print(f\"  R²:   {metrics_rf['r2']:.4f}\")\n",
    "print(f\"  RMSE: {metrics_rf['rmse']:.6f}\")\n",
    "print(f\"  MAE:  {metrics_rf['mae']:.6f}\")\n",
    "print(f\"  Dir Acc: {metrics_rf['directional_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_lgb = model_lgb.predict(X_test)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# LightGBM scatter\n",
    "axes[0, 0].scatter(y_test, y_pred_lgb, alpha=0.5, s=20)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Actual')\n",
    "axes[0, 0].set_ylabel('Predicted')\n",
    "axes[0, 0].set_title(f'LightGBM (R²={metrics_lgb[\"r2\"]:.4f})')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost scatter\n",
    "axes[0, 1].scatter(y_test, y_pred_xgb, alpha=0.5, s=20, color='green')\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Actual')\n",
    "axes[0, 1].set_ylabel('Predicted')\n",
    "axes[0, 1].set_title(f'XGBoost (R²={metrics_xgb[\"r2\"]:.4f})')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest scatter\n",
    "axes[0, 2].scatter(y_test, y_pred_rf, alpha=0.5, s=20, color='orange')\n",
    "axes[0, 2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "axes[0, 2].set_xlabel('Actual')\n",
    "axes[0, 2].set_ylabel('Predicted')\n",
    "axes[0, 2].set_title(f'Random Forest (R²={metrics_rf[\"r2\"]:.4f})')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Time series comparison\n",
    "axes[1, 0].plot(y_test.index, y_test.values, label='Actual', alpha=0.7, linewidth=1.5, color='black')\n",
    "axes[1, 0].plot(y_test.index, y_pred_lgb, label='LightGBM', alpha=0.7, linewidth=1)\n",
    "axes[1, 0].plot(y_test.index, y_pred_xgb, label='XGBoost', alpha=0.7, linewidth=1)\n",
    "axes[1, 0].plot(y_test.index, y_pred_rf, label='Random Forest', alpha=0.7, linewidth=1)\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Returns')\n",
    "axes[1, 0].set_title('Predictions Over Time')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# R² Comparison\n",
    "models = ['LightGBM', 'XGBoost', 'RandomForest']\n",
    "r2_scores = [metrics_lgb['r2'], metrics_xgb['r2'], metrics_rf['r2']]\n",
    "colors_bar = ['steelblue', 'green', 'orange']\n",
    "axes[1, 1].bar(models, r2_scores, color=colors_bar, alpha=0.8)\n",
    "axes[1, 1].set_ylabel('R² Score')\n",
    "axes[1, 1].set_title('Model R² Comparison')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE Comparison\n",
    "rmse_scores = [metrics_lgb['rmse'], metrics_xgb['rmse'], metrics_rf['rmse']]\n",
    "axes[1, 2].bar(models, rmse_scores, color=colors_bar, alpha=0.8)\n",
    "axes[1, 2].set_ylabel('RMSE')\n",
    "axes[1, 2].set_title('Model RMSE Comparison')\n",
    "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Classification Models\n",
    "\n",
    "Using LightGBM for binary and multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Binary Classifier (Up/Down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 4: BINARY LIGHTGBM CLASSIFIER (UP/DOWN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with binary classification\n",
    "model_clf_binary = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTALight,\n",
    "    task='binary_classification'\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_clf_bin = build_features(model_clf_binary, daily_df, intraday_data)\n",
    "\n",
    "# Create binary target\n",
    "y_clf_binary = model_clf_binary.create_clf_target(\n",
    "    n_classes=2,\n",
    "    add_as_feature=False\n",
    ")\n",
    "\n",
    "print(f\"\\nBinary target distribution:\")\n",
    "print(y_clf_binary.value_counts(normalize=True))\n",
    "\n",
    "# Align and split\n",
    "common_idx_bin = X_clf_bin.index.intersection(y_clf_binary.index)\n",
    "X_bin = X_clf_bin.loc[common_idx_bin]\n",
    "y_bin = y_clf_binary.loc[common_idx_bin]\n",
    "\n",
    "split_idx_bin = int(len(X_bin) * 0.8)\n",
    "X_train_bin, X_test_bin = X_bin.iloc[:split_idx_bin], X_bin.iloc[split_idx_bin:]\n",
    "y_train_bin, y_test_bin = y_bin.iloc[:split_idx_bin], y_bin.iloc[split_idx_bin:]\n",
    "\n",
    "val_size_bin = int(len(X_train_bin) * 0.2)\n",
    "X_val_bin = X_train_bin.iloc[-val_size_bin:]\n",
    "y_val_bin = y_train_bin.iloc[-val_size_bin:]\n",
    "X_train_fit_bin = X_train_bin.iloc[:-val_size_bin]\n",
    "y_train_fit_bin = y_train_bin.iloc[:-val_size_bin]\n",
    "\n",
    "# Train\n",
    "print(f\"\\nTraining binary classifier...\")\n",
    "model_clf_binary.fit(\n",
    "    X_train_fit_bin, y_train_fit_bin,\n",
    "    eval_set=(X_val_bin, y_val_bin),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bin = model_clf_binary.predict(X_test_bin)\n",
    "\n",
    "print(f\"\\nBinary Classification Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"  F1 Score:  {f1_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bin, y_pred_bin, target_names=['Down', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_bin = confusion_matrix(y_test_bin, y_pred_bin)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Binary Classification Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Multiclass Classifier (Down/Neutral/Up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 5: MULTICLASS LIGHTGBM CLASSIFIER (DOWN/NEUTRAL/UP)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with multiclass\n",
    "model_clf_multi = IntradayMomentumLight(\n",
    "    intraday_data=intraday_data,\n",
    "    session_open=time(8, 30),\n",
    "    session_end=time(15, 0),\n",
    "    closing_length=timedelta(minutes=60),\n",
    "    tz=\"America/Chicago\",\n",
    "    base_model=CTALight,\n",
    "    task='multiclass',\n",
    "    num_class=3\n",
    ")\n",
    "\n",
    "# Build features\n",
    "X_clf_multi = build_features(model_clf_multi, daily_df, intraday_data)\n",
    "\n",
    "# Create multiclass target with percentile thresholds\n",
    "lower_threshold = target_returns.quantile(0.25)\n",
    "upper_threshold = target_returns.quantile(0.75)\n",
    "\n",
    "y_clf_multi = model_clf_multi.create_clf_target(\n",
    "    n_classes=3,\n",
    "    lower_bound=lower_threshold,\n",
    "    upper_bound=upper_threshold,\n",
    "    add_as_feature=False\n",
    ")\n",
    "\n",
    "print(f\"\\nThresholds:\")\n",
    "print(f\"  Lower (25th %ile): {lower_threshold:.6f}\")\n",
    "print(f\"  Upper (75th %ile): {upper_threshold:.6f}\")\n",
    "\n",
    "print(f\"\\nMulticlass target distribution:\")\n",
    "print(y_clf_multi.value_counts(normalize=True).sort_index())\n",
    "\n",
    "# Align and split\n",
    "common_idx_multi = X_clf_multi.index.intersection(y_clf_multi.index)\n",
    "X_multi = X_clf_multi.loc[common_idx_multi]\n",
    "y_multi = y_clf_multi.loc[common_idx_multi]\n",
    "\n",
    "split_idx_multi = int(len(X_multi) * 0.8)\n",
    "X_train_multi, X_test_multi = X_multi.iloc[:split_idx_multi], X_multi.iloc[split_idx_multi:]\n",
    "y_train_multi, y_test_multi = y_multi.iloc[:split_idx_multi], y_multi.iloc[split_idx_multi:]\n",
    "\n",
    "val_size_multi = int(len(X_train_multi) * 0.2)\n",
    "X_val_multi = X_train_multi.iloc[-val_size_multi:]\n",
    "y_val_multi = y_train_multi.iloc[-val_size_multi:]\n",
    "X_train_fit_multi = X_train_multi.iloc[:-val_size_multi]\n",
    "y_train_fit_multi = y_train_multi.iloc[:-val_size_multi]\n",
    "\n",
    "# Train\n",
    "print(f\"\\nTraining multiclass classifier...\")\n",
    "model_clf_multi.fit(\n",
    "    X_train_fit_multi, y_train_fit_multi,\n",
    "    eval_set=(X_val_multi, y_val_multi),\n",
    "    early_stopping_rounds=50,\n",
    "    num_boost_round=1000\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_multi = model_clf_multi.predict(X_test_multi)\n",
    "\n",
    "print(f\"\\nMulticlass Classification Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test_multi, y_pred_multi):.4f}\")\n",
    "print(f\"  Macro F1: {f1_score(y_test_multi, y_pred_multi, average='macro'):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_multi, y_pred_multi,\n",
    "                          target_names=['Down', 'Neutral', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_multi = confusion_matrix(y_test_multi, y_pred_multi)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Down', 'Neutral', 'Up'],\n",
    "            yticklabels=['Down', 'Neutral', 'Up'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Multiclass Classification Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: Complete Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nREGRESSION MODELS:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model 1 (LightGBM):      R² = {metrics_lgb['r2']:.4f}, RMSE = {metrics_lgb['rmse']:.6f}\")\n",
    "print(f\"Model 2 (XGBoost):       R² = {metrics_xgb['r2']:.4f}, RMSE = {metrics_xgb['rmse']:.6f}\")\n",
    "print(f\"Model 3 (RandomForest):  R² = {metrics_rf['r2']:.4f}, RMSE = {metrics_rf['rmse']:.6f}\")\n",
    "\n",
    "print(\"\\nCLASSIFICATION MODELS (LightGBM):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model 4 (Binary):        Accuracy = {accuracy_score(y_test_bin, y_pred_bin):.4f}, F1 = {f1_score(y_test_bin, y_pred_bin):.4f}\")\n",
    "print(f\"Model 5 (Multiclass):    Accuracy = {accuracy_score(y_test_multi, y_pred_multi):.4f}, F1 = {f1_score(y_test_multi, y_pred_multi, average='macro'):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"✓ IntradayMomentumLight supports multiple base models (LightGBM, XGBoost, RandomForest)\")\n",
    "print(\"✓ Feature engineering is model-agnostic (same features for all models)\")\n",
    "print(\"✓ Regression models compare: LightGBM vs XGBoost vs Random Forest\")\n",
    "print(\"✓ Classification uses LightGBM for binary and multiclass tasks\")\n",
    "print(f\"✓ Best regression model: {['LightGBM', 'XGBoost', 'RandomForest'][np.argmax([metrics_lgb['r2'], metrics_xgb['r2'], metrics_rf['r2']])]}")\n",
    "print(\"✓ All models properly handle temporal splits to avoid lookahead bias\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
